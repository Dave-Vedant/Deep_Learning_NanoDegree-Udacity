{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Dog_Breed_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+U9hHWllnKTocUjpy4cce",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedantdave77/project.Orca/blob/master/Project/project-Dog_Breed_CNN_Classification/CNN_Classifier(PyTorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UX-6DFXWV8",
        "colab_type": "text"
      },
      "source": [
        "# CNN From Scratch \n",
        "\n",
        "---\n",
        "\n",
        "### Embeding Google Drive for Data Access\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xyiUQkS3SUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f4784d7f-c126-4046-802a-317d289eade8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvFxB-eQKT-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set parameters which I usually used during project \n",
        "norm_mean = [0.485, 0.456, 0.406]\n",
        "norm_std = [0.229, 0.224, 0.225]\n",
        "img_short_side_resize = 256\n",
        "img_input_size = 224\n",
        "shuffle = True\n",
        "num_workers = 16\n",
        "batch_size = 64"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZd8GP7Abbk",
        "colab_type": "text"
      },
      "source": [
        "## Data : [Access/ Transform/ Load]\n",
        "\n",
        "Reference: \n",
        "1. [Data Loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
        "\n",
        "2. [Customize Data Set Operation](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
        "\n",
        "3. [Data Transform](https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eprz38e6vwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import required libraries \n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets \n",
        "\n",
        "# define data_transformation and batch_size \n",
        "transform_train = transforms.Compose([\n",
        "                                      transforms.Resize(img_short_side_resize),\n",
        "                                      transforms.ColorJitter(brightness = 0.2, contrast = 0.2, saturation =0.2, hue = 0.1),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomResizedCrop(img_input_size, scale=(0.08,1), ratio = (1,1)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean = norm_mean, std = norm_std)\n",
        "                                       ])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "                                     transforms.Resize(img_input_size),\n",
        "                                     transforms.FiveCrop(img_input_size),\n",
        "                                     transforms.Lambda(lambda crops: torch.stack([\n",
        "                                                                                  transforms.Compose([\n",
        "                                                                                                      transforms.ToTensor(),\n",
        "                                                                                                      transforms.Normalize(mean = norm_mean, std = norm_std)])(crop) for crop in crops\n",
        "                                                                                  ]))\n",
        "\n",
        "                                    ])\n",
        "\n",
        "# load data (define datasets)\n",
        "train_data = datasets.ImageFolder(\"/content/drive/My Drive/Data /dogImages/train/\",transform_train)\n",
        "valid_data = datasets.ImageFolder(\"/content/drive/My Drive/Data /dogImages/valid/\",transform_test)\n",
        "test_data  = datasets.ImageFolder(\"/content/drive/My Drive/Data /dogImages/test/\",transform_test)\n",
        "\n",
        "# separate imput and labels(classes)\n",
        "data = {\"train\" : train_data, \"valid\" : valid_data, \"test\" : test_data}\n",
        "n_classes = len(train_data.classes)\n",
        "\n",
        "# create loaders (train, valid, test)\n",
        "train_loader = torch.utils.data.DataLoader(data[\"train\"], batch_size = batch_size, num_workers = num_workers, shuffle = shuffle, pin_memory = True)\n",
        "valid_loader = torch.utils.data.DataLoader(data[\"valid\"], batch_size = int(np.floor(batch_size/5)), num_workers=0, shuffle = shuffle, pin_memory = True) \n",
        "test_loader = torch.utils.data.DataLoader(data[\"valid\"], batch_size = int(np.floor(batch_size/5)), num_workers=0, shuffle = shuffle, pin_memory = True)\n",
        "\n",
        "# loader dictionary\n",
        "loaders_dict = {\"train\" : train_loader, \"valid\" : valid_loader, \"test\" : test_loader}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhDkeBbHaVbu",
        "colab_type": "text"
      },
      "source": [
        "## Model Architecture :\n",
        "### Create CNN Classifier \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKhROf00XuHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# generate the CNN Architecture from Scratch\n",
        "class CNN(nn.module):\n",
        "    def __init__(self,n_classes,layer1_depth = 32):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        # define layer wise depth\n",
        "        layer2_depth = layer1_depth *2                                         # 32 --> 64\n",
        "        layer3_depth = layer2_depth *2                                         # 64 --> 128\n",
        "\n",
        "        # define Max-pooling layer\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "        # convolution set 1 \n",
        "        self.conv1_1 = nn.Conv2d(3, layer1_depth, 3, stride=1, padding=1)\n",
        "        self.conv1_2 = nn.Conv2d(layer1_depth, layer1_depth, 3, stride=1, padding=1)\n",
        "        self.conv1_3 = nn.Conv2d(layer1_depth, layer1_depth, 3, stride=1, padding=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(layer1_depth)\n",
        "        self.bn1_2 = nn.BatchNorm2d(layer1_depth)\n",
        "        self.bn1_3 = nn.BatchNorm2d(layer1_depth)\n",
        "\n",
        "        # convolution set 2 \n",
        "        self.conv2_1 = nn.Conv2d(layer1_depth, layer2_depth, 3, stride=1, padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(layer2_depth, layer2_depth, 3, stride=1, padding=1)\n",
        "        self.conv2_3 = nn.Conv2d(layer2_depth, layer2_depth, 3, stride=1, padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(layer2_depth)\n",
        "        self.bn2_2 = nn.BatchNorm2d(layer2_depth)\n",
        "        self.bn2_3 = nn.BatchNorm2d(layer2_depth)\n",
        "\n",
        "        # convolution set 3 \n",
        "        self.conv3_1 = nn.Conv2d(layer2_depth, layer3_depth, 3, stride=1, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(layer3_depth, layer3_depth, 3, stride=1, padding=1)\n",
        "        self.conv3_3 = nn.Conv2d(layer3_depth, layer3_depth, 3, stride=1, padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(layer3_depth)\n",
        "        self.bn3_2 = nn.BatchNorm2d(layer3_depth)\n",
        "        self.bn3_3 = nn.BatchNorm2d(layer3_depth)\n",
        "\n",
        "        # output \n",
        "        self.output = nn.Linear(layer3_depth,n_classes)                         # 128 ---> 133\n",
        "\n",
        "        # Initialize weight\n",
        "        nn.init.kaiming_normal_(self.conv1_1.weight, nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv1_2.weight, nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv1_3.weight, nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv2_1.weight, nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv2_2.weight, nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv2_3.weight, nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv3_1.weight, nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv3_2.weight, nonlinearity='relu') \n",
        "        nn.init.kaiming_normal_(self.conv3_3.weight, nonlinearity='relu')       \n",
        "\n",
        "\n",
        "\"\"\" \n",
        "Develop forward pass, with feature expandation and \n",
        "extraction by increase or maintain depthh of network. \n",
        "\n",
        "\"\"\" \n",
        "\n",
        "    def forward(self,x):\n",
        "        # Conv Flow 1\n",
        "        x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
        "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
        "        x = F.relu(self.bn1_3(self.conv1_3(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Conv Flow 2\n",
        "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "        x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
        "        x = F.relu(self.bn2_3(self.conv2_3(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Conv Flow 3\n",
        "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
        "        x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
        "        x = F.relu(self.bn3_3(self.conv3_3(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # fuse the dimension (height=2, width =3)\n",
        "        x = x.view(x.size(0),x.size(1),-1)\n",
        "        x = x.max(2)[0]\n",
        "\n",
        "        # output \n",
        "        x = self.output(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kXE60g40WDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_scratch = CNN(n_classes)\n",
        "\n",
        "if use_cuda:\n",
        "    model_scratch.cuda()           "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}