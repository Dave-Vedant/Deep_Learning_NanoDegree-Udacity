{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQB6Vx2g1kjn"
   },
   "source": [
    "# Sentimental_Analysis using AWS sagemaker - XGBoost algorithm\n",
    "[Vedant Dave](https://vedantdave77.github.io/) | Vedantdave77@gmail.com | [LinkedIn](https://www.linkedin.com/in/vedant-dave117/)\n",
    "\n",
    "Hello, I am Vedant Dave, a machine learning practitioner data enthusiast professional. -@dave117\n",
    "\n",
    "## Intro:\n",
    "In this notebook, I am going to analyze IMDB dataset. Its one of the best dagtaset of NLP research. You can search about IMDB on IMDB.com to get an idea about the company portfolio and their workprofile. Well, my main purpose is to use AWS-Sagemaker's python SDK - xgboost module for Sentiment-Anlysis.\n",
    "\n",
    "Why?\n",
    "\n",
    "- For most of online websites and ecommerce/ digital communication companies, sentimental analysis is one of the major field to improve customer satisfaction, which leads to business growth. \n",
    "\n",
    "- My Major goal is to analyze (preparation of text data and implement a AWS model with sagemaker (batch-transform method). I am also going to make deployment using lambda function (with another notebook). The data storage will be S3 data storage. \n",
    "\n",
    "- The credit for this notebook goes to Udacity, from which I took an intuition, but the code modification, improvement and procedure explaination done by me. So, for any specific issue with notebook you can connect with me on above contact ID, and I request you to use right side of google tab for searching about more explaination. Thank you. \n",
    "\n",
    "---\n",
    "\n",
    "Project ML Flow: **Standford Data API -- S3 -- SageMaker -- Lambda -- WebApp(html file)** \n",
    "\n",
    "---\n",
    "\n",
    "So, let's start...\n",
    "\n",
    "### Download data from [IMDB dataset](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "Current format of data is One file, for project we need to seperate them in train, validation and test datasets. The labels are also in pos/ neg form so, for project, its better to covert them in 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "ppskPPw6UlL0",
    "outputId": "94db716d-fec3-4320-c843-636fa4f478c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-12 22:12:31--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘../data/aclImdb_v1.tar.gz’\n",
      "\n",
      "../data/aclImdb_v1. 100%[===================>]  80.23M  45.0MB/s    in 1.8s    \n",
      "\n",
      "2020-06-12 22:12:33 (45.0 MB/s) - ‘../data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%mkdir ../data                                                                                         # create directory\n",
    "!wget -O ../data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz      # download data with !wget --> its gnu fun. helps to download http://* data\n",
    "!tar -zxf ../data/aclImdb_v1.tar.gz -C ../data                                                          # extract .tar file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9APSOWD5fXU"
   },
   "source": [
    "### Data Preparation\n",
    "Data is downloaded in one file, we first need to create them in train and test set, with dataset and lablels. \n",
    "> We are also going to use predictive analysis, so its better to change label in 1 and 0, instead of pos and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcQ9psFh5d_i"
   },
   "outputs": [],
   "source": [
    "import os                                                                       # provide operating system accordingly ...\n",
    "import glob                                                                     # glob is path name matcher, start each file with .*\n",
    "\n",
    "def read_data(data_dir='../data/aclImdb'):\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for data_type in ['train', 'test']:\n",
    "        data[data_type] = {}\n",
    "        labels[data_type] = {}\n",
    "        \n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            data[data_type][sentiment] = []\n",
    "            labels[data_type][sentiment] = []\n",
    "            \n",
    "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
    "            files = glob.glob(path)\n",
    "            \n",
    "            for f in files:\n",
    "                with open(f) as review:\n",
    "                    data[data_type][sentiment].append(review.read())\n",
    "                    # Here we represent a positive review by '1' and a negative review by '0'\n",
    "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
    "                    \n",
    "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
    "                \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8T3xzaL5d8O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IMDB reviews : train = 12500 pos/ 12500 neg, test = 12500 pos / 12500 neg\n"
     ]
    }
   ],
   "source": [
    "data,labels = read_data()\n",
    "print(\"Total IMDB reviews : train = {} pos/ {} neg, test = {} pos / {} neg\".\n",
    "      format(len(data['train']['pos']),len(data['train']['neg']),\n",
    "             len(data['test']['pos']),len(data['test']['neg'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tF6poUq5d6d"
   },
   "outputs": [],
   "source": [
    "# Now, lets conmbine pos and neg dataset and shuffle them for making training and testing dataset.\n",
    "# WHY?  --> because, form above function we get four sets separated by pos, neg in train and test set... (look and understand)\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_imdb_data(data,lables):\n",
    "    data_train = data['train']['pos'] + data['train']['neg']\n",
    "    data_test = data['test']['pos'] + data['test']['neg']\n",
    "    labels_train = labels['train']['pos'] + labels['train']['neg']              # Awesome mistake +++ cost me 8 days (and 50+ hr sagemaker cost)\n",
    "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
    "\n",
    "    # shuffle reviews and correspoing labels within training and test dataset\n",
    "    data_train, labels_train = shuffle(data_train,labels_train)                 # this helps us to shuffle through whole training ...\n",
    "    data_test, labels_test = shuffle(data_test,labels_test)\n",
    "\n",
    "    # return a datasets for future processes.\n",
    "    return data_train, data_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72F89VYF5d3-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB total reviews (full dataset) :train = 25000, test - 25000\n"
     ]
    }
   ],
   "source": [
    "train_X,test_X,train_y,test_y = prepare_imdb_data(data,labels)\n",
    "print('IMDB total reviews (full dataset) :train = {}, test - {}'.format(len(train_X),len(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hz3K6bEW5d1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rock n' roll is a messy business and DiG! demonstrates this masterfully. A project of serious ambition, and perhaps foolhardiness, the filmmaker is able to mend together seven tumultuous years of following around two unwieldy rock groups. With that said, the abundance of quality material ensures the film's ability to captivate the audience. If you've ever been interested in any realm of the music industry, this movie will undoubtedly be an arresting viewing. the music in the film, although it suffers minimally from requisite cutting and pasting, is worth the price of admission alone. the morning after i saw DiG! i went straight to the record store to pick up a Brian Jonestown Massacre album (i was already initiated to the Dandy Warhols' sounds). Primarily defined by its exploration of rock music, the film succeeds at other profound levels. DiG! is a sincere, and sufficiently objective, glance into the destructive and volatile nature of the creative process and the people that try to wrangle those forces.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[100]                                                                    #  first 100 reviews (.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTH0SAFrARcS"
   },
   "source": [
    "### Data Preprocessing\n",
    "The complex problem in ML is to clean data, and make them ready for analysis. Here, please observe above review. We downloaded from web in html form. That's why you can see html format **(<!br>  \\</!br>)** there. So, first we need to remove them. More over, some words are repetative, meaning less and with similar meaning. So, first we will remove all these obsecles. The step is called data preprocessing, also know as data cleaning, dfata wrangling, data manipulation. So, I am going to use NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "whAo52i55dzJ",
    "outputId": "7f6544a3-24e1-4505-9908-5db0b5f6972d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")                                # does not work, need to download from specific library directory.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *                          \n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fkaxgV35dwf"
   },
   "outputs": [],
   "source": [
    "import re                                                     # import request.\n",
    "from bs4 import BeautifulSoup                                 # python library for html and css parsing(remove format stye...) \n",
    "\n",
    "def review_to_words(review):\n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text()                      # remove html tags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\",\" \",text.lower())                             # conver to lowercase (all a to z, A to Z, 0 to 9)\n",
    "    words = text.split()                                                        # split string into words\n",
    "    words = [w for w in words if  w not in stopwords.words(\"english\")]          # remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words]                           # stem --> nlp library for stemmers (prular words, languages, similarity etc...)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8OSjE7C5dtR"
   },
   "outputs": [],
   "source": [
    "import pickle                                                                   # for serializing/deserializing python input (here,pickle--> converts datastructure to byte stram)\n",
    "cache_dir = os.path.join(\"../cache\", \"sentiment_analysis\")                      # define storage path\n",
    "os.makedirs(cache_dir, exist_ok=True)                                           # ensure about directory\n",
    "\n",
    "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
    "                    cache_dir = cache_dir, cache_file =\"preprocessed_data.pkl\"):\n",
    "  \n",
    "    cache_data = None                                          # initialize cach data\n",
    "    if cache_file is not None:                                 # comp saved cache data for future purpose so, the operation will be faster \n",
    "        try: \n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:           # read bite form pickle file\n",
    "                cache_data = pickle.load(f)\n",
    "            print(\"Read preprocessed data from cache file :\" , cache_file)\n",
    "        except:\n",
    "            pass                       \n",
    "\n",
    "    if cache_data is None:\n",
    "        words_train = [review_to_words(review) for review in data_train]    # generate list [] from available dict. \"data_train\"\n",
    "        words_test = [review_to_words(review) for review in data_test]     # ... same \n",
    "\n",
    "        if cache_file is not None:\n",
    "            cache_data = dict(words_train = words_train,words_test = words_test, labels_train = labels_train,labels_test=labels_test)\n",
    "        with open(os.path.join(cache_dir, cache_file),\"wb\") as f:\n",
    "            pickle.dump(cache_data,f)\n",
    "            print(\"Wrote preprocessed data to cache file: \", cache_file)\n",
    "    else: \n",
    "        print(\"Getting from cache data ...\")\n",
    "        words_train,words_test,labels_train,labels_test = (cache_data['words_train'],cache_data['words_test'],cache_data['labels_train'],cache_data['labels_test'])\n",
    "      \n",
    "    return words_train,words_test,labels_train,labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fix8k_YI0h4_"
   },
   "source": [
    "**Explainations of preprocess operation:** \n",
    "\n",
    "Here, We had two options, \n",
    "> first one **load data directly from cache_file,which generated previously. If does not exist, then** and then move to cache_data....\n",
    ">> (A)  Now, first **check the data existance as cache_data**, if it is there in **empty cache_data, then generate train and test list** for cache_data  and also write operation (dump) to **fill the cache_file.** So, for future purpose our data will be taken from cache_file.<br>\n",
    ">> (B) But, **if cache_data is already exists, then better to load data** from it,to save time.\n",
    "\n",
    "Still, in case of confusion!, its better to make a flow diagram on paper ownself. ;) :).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6m_r9Ubz-BU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote preprocessed data to cache file:  preprocessed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# get preprocessed data\n",
    "train_X,test_X,train_y,test_y = preprocess_data(train_X,test_X,train_y,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Bag of words features \n",
    "\n",
    "\n",
    "The bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity.\n",
    "\n",
    "\n",
    "As an example : \n",
    "\n",
    "> Sentence : I like data science, it is the exploration behind data. Please, give me an opportunity to work with data science\n",
    ">> Bag of words = {\"I\" = 1, \"like\":1, \"data\" :3, science\" :2 , \"it\":1, ... ,\"with\" : 1};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIygdc2fz9-C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.externals import joblib                                            # joblib is advanced pickle version used for storing numpy arrays (bite-pyhton_moduel-bite\n",
    "\n",
    "def extract_BoW_features(words_train,words_test,vocabulary_size = 5000,\n",
    "                         cache_dir = cache_dir, cache_file = 'bow_features.pkl'):\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), 'rb') as f:\n",
    "                cache_data = joblib.load(f)\n",
    "            print(\"Read features from cache file: \", cache_file)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if cache_data is None:\n",
    "        vectorizer = CountVectorizer(max_features = vocabulary_size ,\n",
    "                                     preprocessor = lambda x: x,tokenizer = lambda x:x)\n",
    "        features_train = vectorizer.fit_transform(words_train).toarray()\n",
    "        features_test = vectorizer.transform(words_test).toarray()\n",
    "\n",
    "        if cache_file is not None:\n",
    "            vocabulary = vectorizer.vocabulary_\n",
    "            cache_data = dict(features_train = features_train,features_test=features_test,\n",
    "                            vocabulary = vocabulary)\n",
    "            with open(os.path.join(cache_dir, cache_file),'wb') as f:\n",
    "                joblib.dump(cache_data,f)\n",
    "            print(\"wrote features to cache file:\",cache_file)\n",
    "    else:\n",
    "        features_train, features_test,vocabulary = (cache_data['features_train'],cache_data['features_test'],\n",
    "                                                    cache_data['vocabulary'])\n",
    "\n",
    "    return features_train, features_test, vocabulary\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMP5eYvRz98O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote features to cache file: bow_features.pkl\n"
     ]
    }
   ],
   "source": [
    "train_X,test_X,vocabulary = extract_BoW_features(train_X,test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1vzcPtmJ8d1"
   },
   "source": [
    "### Classification using  XGBoost Algorithm\n",
    "SageMaker has predefined XGBoost Algirthm for classificatio task. But for better accuracy and avoid overfitting I want to use validation dataset. For that, first we will give first 10000 review to validation and then give data to XGBoost in panda dataframe format. The data is stored in S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0eP9fpBz94U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "val_X = pd.DataFrame(train_X[:10000])\n",
    "train_X = pd.DataFrame(train_X[10000:])\n",
    "\n",
    "val_y = pd.DataFrame(train_y[:10000])\n",
    "train_y = pd.DataFrame(train_y[10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_PmpEvrJFJV"
   },
   "outputs": [],
   "source": [
    "# generate local dictionary where our data is stored for use.\n",
    "data_dir = '../data/xgboost'\n",
    "if not os.path.exists(data_dir):                                                # ensure about dir. (resolve bug)\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     3     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
       "0     0     0     0     0     1     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     1     0     0     0     0     0     0  ...     0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  0\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdWcpT9MJGE9"
   },
   "outputs": [],
   "source": [
    "# save data to dictionary \n",
    "pd.DataFrame(test_X).to_csv(os.path.join(data_dir,'test.csv'),header=False,index=False)                         # test.csv \n",
    "\n",
    "pd.concat([val_y,val_X],axis=1).upload_data(os.path.join(data_dir,'validation.csv'),header= False, index= False)   # validation.csv\n",
    "\n",
    "pd.concat([train_y,train_X],axis=1).upload_data(os.path.join(data_dir,'train.csv'),header= False, index = False)   # train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUyJKTpSJGBk"
   },
   "outputs": [],
   "source": [
    "# initialize memory storage (so, set a bit of memory to None)\n",
    "train_X = val_X = train_y = val_y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTBGZKQwjk9_"
   },
   "source": [
    "### Uploading Training/validation to S3 \n",
    "Flow --> Local_dir --> S3 --> SageMaker --> S3(result) --> Local_dir(result)\n",
    "\n",
    "Here, I am going to use sagemaker's high level features so, all the background work will be done by sagemaker ownself, and I just need to provide resources, commands and requirements to sagemaker. \n",
    "\n",
    "There is posibility of Low level fetaures, which give us chance to provide flexiblility to model, but when you need to do some research around your result. Well, here in future I will use auto Hyper parameter tuning, to get best answer (with high accuracy) for our dataset problem. So, its nice to use highlevel features.\n",
    "\n",
    "Let's start real work with SAGEMAKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAgduC9cJF_r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n",
      "'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n",
      "'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker                                                                # call sagemaker\n",
    "session = sagemaker.Session()                                                   # create  session for sagemaker \n",
    "prefix = 'sentiment-xgboost-hptuning'                                                    # prefix will be used for unique name identification (in near future)\n",
    "\n",
    "# set specific location on S3 for easy access \n",
    "test_location = session.upload_data(os.path.join(data_dir,'test.csv'),key_prefix= prefix)           # upload test data \n",
    "val_location = session.upload_data(os.path.join(data_dir,'validation.csv'),key_prefix = prefix)    # upload validation data\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'),key_prefix = prefix)        # upload train data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiKQEHwDmq8-"
   },
   "source": [
    "### Create XGBoost model tuning requirement\n",
    "\n",
    "As I declared before, I am using high level API, helps me to get answer quickly without more flexibility. But, after auto tuing we will get the best answer. Now, here before training, we need to do some setup. \n",
    "\n",
    "Sagemaker model creation : it's ecosystem has three different objects, which are interactive with eachother. \n",
    "1. Model Artifacts\n",
    "2. Training Code (container)\n",
    "3. Inference Code (container)\n",
    "\n",
    "Model artifact is Model itself. The training code use training data, and create model artifacts. Inference code use the model artifacts to predict new data. \n",
    "\n",
    "Sagemaker use docker containers. So, after all docker container is one kind of package of code with proper sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALl4hkN0mqmc"
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role                                          \n",
    "role = get_execution_role()                                                     # create model execution role = IAM role, for giving permission to specific person or user group (to control unauthorize access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vb1NhGwQJF8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.amazon.amazon_estimator:'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(session.boto_region_name,'xgboost')                   # set container for giving private space to model (when you have more than one deploying model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dE_CFWjLJF6W"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# specify model with requried parameters \n",
    "xgb = sagemaker.estimator.Estimator(container,                                  # initialize modelxgb = sagemaker.estimator.Estimator(container,                                  # define container (where to take data)\n",
    "                                    role,                                       # define role (who give permission for this)\n",
    "                                    train_instance_count = 1,                   # instance will used for task (more instance, more power, more expense)\n",
    "                                    train_instance_type = 'ml.m4.xlarge',       # power of isntance (more power, more expense, less execution time) , its different than your notebook instance. \n",
    "                                    output_path = 's3://{}/{}/output'.format(session.default_bucket(),prefix),   # where to save\n",
    "                                    sagemaker_session= session)                 # define session (the current one)\n",
    "\n",
    "\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,                                             # set parameters\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEMW2RD2-3tD"
   },
   "source": [
    "### create the hyper_parameter tuner...\n",
    "Here, you can give range of parameters and your model will automatically takes the value from that range. I gave total 10 models to decide the best one. ... means it takes the parameter from the range and will return the best model on the base of traning and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JFJIrHs-4VV"
   },
   "outputs": [],
   "source": [
    "# Aided section for Hyper parameter\n",
    "from sagemaker.tuner import IntegerParameter,ContinuousParameter,HyperparameterTuner      # please observe capitals and speling (bug detected --> fixed)\n",
    "\n",
    "# xgb_hyperparameter_tuner = None\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:rmse', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Minimize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 6, # The total number of models to train\n",
    "                                               max_parallel_jobs = 3, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FTRnt9obAzNf"
   },
   "source": [
    "### Fit the hyperparameter tuner (same as model fitting)\n",
    "We already defined model, and also generated the model data. \n",
    "\n",
    "Now the next step will be to fit data within model. Means... train our model on dataset. It takes time and for training you have two options in term of instance capacity. \n",
    "\n",
    "For me **m1.m4.xlarge** is still in free-tier hours(125hr). So, I am going to use it. otherwise the notebook instance **(m1.m5.xlarge)** which I used is better than this. But, as I discussed earlier **I had problem with cache data of instance memory. So, I used high power model building instance.** You are free to use any. \n",
    "> *Please refer the Sagemaker documentation for more information regarding price and capacity. Thank you*\n",
    "\n",
    "---\n",
    "\n",
    "Following procedure will take some more time around 30 to 40 min...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udjcJQxvJF33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data = train_location,content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data = val_location, content_type= 'csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train,'validation': s3_input_validation})\n",
    "\n",
    "xgb_hyperparameter_tuner.wait()                      ### This will give us final message. For more inforatin, you should check the log_file in sagemaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QbeDszgHth8g"
   },
   "source": [
    "### Testing Model\n",
    "\n",
    "I will use SageMakers Batch Transform functionality.\n",
    "\n",
    "Batch Transform is a convenient way to perform inference on a large dataset in a way that is not realtime. That is, we don't necessarily need to use our model's results immediately and instead we can peform inference on a large number of samples.\n",
    "\n",
    "**Applications:**\n",
    ">Industries, which run their business continueously and want to predict their growth and customer service periodically, may be at the end of week, or end of month. They will use batch transform. So, its not used for realtime applications. Small businesses mostly use it. Sometime industry giants use it for specific problem solution. (as an example, some specific region have issue with specific type of product, then for 5W QA analysis they can use it.) \n",
    "\n",
    "---\n",
    "the following procedure takes some time 5 to 10 min... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWrRgrKmBf5F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-12 23:59:55 Starting - Preparing the instances for training\n",
      "2020-06-12 23:59:55 Downloading - Downloading input data\n",
      "2020-06-12 23:59:55 Training - Training image download completed. Training in progress.\n",
      "2020-06-12 23:59:55 Uploading - Uploading generated training model\n",
      "2020-06-12 23:59:55 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-06-12:23:42:48:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-06-12:23:42:48:INFO] Setting up HPO optimized metric to be : rmse\u001b[0m\n",
      "\u001b[34m[2020-06-12:23:42:48:INFO] File size need to be processed in the node: 238.47mb. Available memory size in the node: 8477.12mb\u001b[0m\n",
      "\u001b[34m[2020-06-12:23:42:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:42:48] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:42:50] 15000x5000 matrix with 75000000 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-06-12:23:42:50:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:42:50] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:42:51] 10000x5000 matrix with 50000000 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[23:42:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.485731#011validation-rmse:0.486439\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[23:42:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.473561#011validation-rmse:0.475149\u001b[0m\n",
      "\u001b[34m[23:43:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.463087#011validation-rmse:0.465347\u001b[0m\n",
      "\u001b[34m[23:43:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.454032#011validation-rmse:0.456792\u001b[0m\n",
      "\u001b[34m[23:43:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.44603#011validation-rmse:0.449542\u001b[0m\n",
      "\u001b[34m[23:43:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.438837#011validation-rmse:0.442923\u001b[0m\n",
      "\u001b[34m[23:43:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.432403#011validation-rmse:0.437366\u001b[0m\n",
      "\u001b[34m[23:43:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.426526#011validation-rmse:0.432427\u001b[0m\n",
      "\u001b[34m[23:43:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.421234#011validation-rmse:0.427918\u001b[0m\n",
      "\u001b[34m[23:43:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.41647#011validation-rmse:0.42391\u001b[0m\n",
      "\u001b[34m[23:43:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.411622#011validation-rmse:0.420031\u001b[0m\n",
      "\u001b[34m[23:43:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.407505#011validation-rmse:0.416368\u001b[0m\n",
      "\u001b[34m[23:43:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.403536#011validation-rmse:0.413103\u001b[0m\n",
      "\u001b[34m[23:43:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.400062#011validation-rmse:0.410062\u001b[0m\n",
      "\u001b[34m[23:43:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.396527#011validation-rmse:0.407114\u001b[0m\n",
      "\u001b[34m[23:43:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.393286#011validation-rmse:0.404447\u001b[0m\n",
      "\u001b[34m[23:43:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.389854#011validation-rmse:0.401565\u001b[0m\n",
      "\u001b[34m[23:43:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.38685#011validation-rmse:0.399195\u001b[0m\n",
      "\u001b[34m[23:43:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.383781#011validation-rmse:0.396747\u001b[0m\n",
      "\u001b[34m[23:43:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.381071#011validation-rmse:0.394493\u001b[0m\n",
      "\u001b[34m[23:43:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.377867#011validation-rmse:0.39233\u001b[0m\n",
      "\u001b[34m[23:43:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.375282#011validation-rmse:0.390057\u001b[0m\n",
      "\u001b[34m[23:43:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.372948#011validation-rmse:0.388167\u001b[0m\n",
      "\u001b[34m[23:43:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.370664#011validation-rmse:0.38623\u001b[0m\n",
      "\u001b[34m[23:44:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.368126#011validation-rmse:0.384325\u001b[0m\n",
      "\u001b[34m[23:44:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.365817#011validation-rmse:0.382609\u001b[0m\n",
      "\u001b[34m[23:44:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.36382#011validation-rmse:0.380992\u001b[0m\n",
      "\u001b[34m[23:44:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.361688#011validation-rmse:0.379094\u001b[0m\n",
      "\u001b[34m[23:44:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.359768#011validation-rmse:0.377735\u001b[0m\n",
      "\u001b[34m[23:44:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.357871#011validation-rmse:0.376225\u001b[0m\n",
      "\u001b[34m[23:44:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.355802#011validation-rmse:0.37467\u001b[0m\n",
      "\u001b[34m[23:44:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.353875#011validation-rmse:0.373017\u001b[0m\n",
      "\u001b[34m[23:44:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.352198#011validation-rmse:0.371537\u001b[0m\n",
      "\u001b[34m[23:44:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 32 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.350147#011validation-rmse:0.370312\u001b[0m\n",
      "\u001b[34m[23:44:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.348466#011validation-rmse:0.369058\u001b[0m\n",
      "\u001b[34m[23:44:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 36 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.346628#011validation-rmse:0.367868\u001b[0m\n",
      "\u001b[34m[23:44:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.345037#011validation-rmse:0.367047\u001b[0m\n",
      "\u001b[34m[23:44:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 32 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.343439#011validation-rmse:0.365956\u001b[0m\n",
      "\u001b[34m[23:44:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.342007#011validation-rmse:0.364856\u001b[0m\n",
      "\u001b[34m[23:44:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.340567#011validation-rmse:0.363612\u001b[0m\n",
      "\u001b[34m[23:44:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.339275#011validation-rmse:0.362658\u001b[0m\n",
      "\u001b[34m[23:44:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.337871#011validation-rmse:0.361631\u001b[0m\n",
      "\u001b[34m[23:44:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.336412#011validation-rmse:0.360783\u001b[0m\n",
      "\u001b[34m[23:44:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.3352#011validation-rmse:0.360111\u001b[0m\n",
      "\u001b[34m[23:44:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.333647#011validation-rmse:0.359092\u001b[0m\n",
      "\u001b[34m[23:44:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.332346#011validation-rmse:0.358154\u001b[0m\n",
      "\u001b[34m[23:44:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.330769#011validation-rmse:0.357258\u001b[0m\n",
      "\u001b[34m[23:45:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.329739#011validation-rmse:0.356263\u001b[0m\n",
      "\u001b[34m[23:45:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.328573#011validation-rmse:0.355286\u001b[0m\n",
      "\u001b[34m[23:45:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.327365#011validation-rmse:0.354409\u001b[0m\n",
      "\u001b[34m[23:45:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:0.326042#011validation-rmse:0.353745\u001b[0m\n",
      "\u001b[34m[23:45:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:0.325031#011validation-rmse:0.353142\u001b[0m\n",
      "\u001b[34m[23:45:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:0.323712#011validation-rmse:0.352358\u001b[0m\n",
      "\u001b[34m[23:45:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:0.322561#011validation-rmse:0.351746\u001b[0m\n",
      "\u001b[34m[23:45:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:0.321641#011validation-rmse:0.351117\u001b[0m\n",
      "\u001b[34m[23:45:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:0.320535#011validation-rmse:0.350096\u001b[0m\n",
      "\u001b[34m[23:45:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:0.319215#011validation-rmse:0.349206\u001b[0m\n",
      "\u001b[34m[23:45:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:0.318122#011validation-rmse:0.348544\u001b[0m\n",
      "\u001b[34m[23:45:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:0.316996#011validation-rmse:0.347809\u001b[0m\n",
      "\u001b[34m[23:45:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:0.316073#011validation-rmse:0.346973\u001b[0m\n",
      "\u001b[34m[23:45:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:0.31452#011validation-rmse:0.346292\u001b[0m\n",
      "\u001b[34m[23:45:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:0.313579#011validation-rmse:0.345702\u001b[0m\n",
      "\u001b[34m[23:45:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:0.312264#011validation-rmse:0.345073\u001b[0m\n",
      "\u001b[34m[23:45:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:0.311399#011validation-rmse:0.344454\u001b[0m\n",
      "\u001b[34m[23:45:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:0.310401#011validation-rmse:0.343924\u001b[0m\n",
      "\u001b[34m[23:45:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.308988#011validation-rmse:0.343343\u001b[0m\n",
      "\u001b[34m[23:45:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:0.308271#011validation-rmse:0.34283\u001b[0m\n",
      "\u001b[34m[23:45:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:0.307165#011validation-rmse:0.342293\u001b[0m\n",
      "\u001b[34m[23:45:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:0.306356#011validation-rmse:0.34178\u001b[0m\n",
      "\u001b[34m[23:46:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[69]#011train-rmse:0.305528#011validation-rmse:0.341295\u001b[0m\n",
      "\u001b[34m[23:46:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:0.304282#011validation-rmse:0.340647\u001b[0m\n",
      "\u001b[34m[23:46:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:0.302898#011validation-rmse:0.340172\u001b[0m\n",
      "\u001b[34m[23:46:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:0.30198#011validation-rmse:0.339632\u001b[0m\n",
      "\u001b[34m[23:46:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:0.301255#011validation-rmse:0.339125\u001b[0m\n",
      "\u001b[34m[23:46:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:0.300503#011validation-rmse:0.338639\u001b[0m\n",
      "\u001b[34m[23:46:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:0.299901#011validation-rmse:0.338087\u001b[0m\n",
      "\u001b[34m[23:46:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[76]#011train-rmse:0.299181#011validation-rmse:0.33769\u001b[0m\n",
      "\u001b[34m[23:46:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[77]#011train-rmse:0.298463#011validation-rmse:0.337278\u001b[0m\n",
      "\u001b[34m[23:46:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[78]#011train-rmse:0.297534#011validation-rmse:0.336959\u001b[0m\n",
      "\u001b[34m[23:46:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[79]#011train-rmse:0.296788#011validation-rmse:0.3366\u001b[0m\n",
      "\u001b[34m[23:46:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[80]#011train-rmse:0.296215#011validation-rmse:0.33625\u001b[0m\n",
      "\u001b[34m[23:46:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[81]#011train-rmse:0.295435#011validation-rmse:0.335939\u001b[0m\n",
      "\u001b[34m[23:46:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[82]#011train-rmse:0.2947#011validation-rmse:0.335515\u001b[0m\n",
      "\u001b[34m[23:46:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[83]#011train-rmse:0.294055#011validation-rmse:0.335162\u001b[0m\n",
      "\u001b[34m[23:46:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[84]#011train-rmse:0.293224#011validation-rmse:0.334697\u001b[0m\n",
      "\u001b[34m[23:46:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[85]#011train-rmse:0.292644#011validation-rmse:0.334357\u001b[0m\n",
      "\u001b[34m[23:46:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[86]#011train-rmse:0.291931#011validation-rmse:0.333924\u001b[0m\n",
      "\u001b[34m[23:46:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[87]#011train-rmse:0.291229#011validation-rmse:0.333468\u001b[0m\n",
      "\u001b[34m[23:46:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[88]#011train-rmse:0.290419#011validation-rmse:0.332954\u001b[0m\n",
      "\u001b[34m[23:46:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[89]#011train-rmse:0.289766#011validation-rmse:0.332572\u001b[0m\n",
      "\u001b[34m[23:46:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[90]#011train-rmse:0.288976#011validation-rmse:0.332254\u001b[0m\n",
      "\u001b[34m[23:46:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[91]#011train-rmse:0.288325#011validation-rmse:0.331992\u001b[0m\n",
      "\u001b[34m[23:47:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[92]#011train-rmse:0.287448#011validation-rmse:0.331651\u001b[0m\n",
      "\u001b[34m[23:47:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[93]#011train-rmse:0.286861#011validation-rmse:0.33127\u001b[0m\n",
      "\u001b[34m[23:47:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[94]#011train-rmse:0.286036#011validation-rmse:0.330955\u001b[0m\n",
      "\u001b[34m[23:47:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[95]#011train-rmse:0.285474#011validation-rmse:0.330645\u001b[0m\n",
      "\u001b[34m[23:47:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[96]#011train-rmse:0.285026#011validation-rmse:0.330115\u001b[0m\n",
      "\u001b[34m[23:47:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[97]#011train-rmse:0.28468#011validation-rmse:0.329748\u001b[0m\n",
      "\u001b[34m[23:47:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[98]#011train-rmse:0.28396#011validation-rmse:0.329477\u001b[0m\n",
      "\u001b[34m[23:47:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[99]#011train-rmse:0.283322#011validation-rmse:0.329156\u001b[0m\n",
      "\u001b[34m[23:47:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[100]#011train-rmse:0.282683#011validation-rmse:0.328804\u001b[0m\n",
      "\u001b[34m[23:47:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[101]#011train-rmse:0.281969#011validation-rmse:0.328457\u001b[0m\n",
      "\u001b[34m[23:47:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[102]#011train-rmse:0.281458#011validation-rmse:0.328045\u001b[0m\n",
      "\u001b[34m[23:47:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[103]#011train-rmse:0.280848#011validation-rmse:0.327756\u001b[0m\n",
      "\u001b[34m[23:47:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[104]#011train-rmse:0.280304#011validation-rmse:0.327498\u001b[0m\n",
      "\u001b[34m[23:47:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[105]#011train-rmse:0.2798#011validation-rmse:0.327177\u001b[0m\n",
      "\u001b[34m[23:47:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[106]#011train-rmse:0.279143#011validation-rmse:0.326948\u001b[0m\n",
      "\u001b[34m[23:47:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[107]#011train-rmse:0.278663#011validation-rmse:0.326668\u001b[0m\n",
      "\u001b[34m[23:47:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[108]#011train-rmse:0.278176#011validation-rmse:0.326468\u001b[0m\n",
      "\u001b[34m[23:47:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[109]#011train-rmse:0.277557#011validation-rmse:0.326347\u001b[0m\n",
      "\u001b[34m[23:47:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[110]#011train-rmse:0.276901#011validation-rmse:0.326044\u001b[0m\n",
      "\u001b[34m[23:47:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[111]#011train-rmse:0.276306#011validation-rmse:0.325777\u001b[0m\n",
      "\u001b[34m[23:47:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[112]#011train-rmse:0.275957#011validation-rmse:0.325605\u001b[0m\n",
      "\u001b[34m[23:47:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[113]#011train-rmse:0.275441#011validation-rmse:0.325332\u001b[0m\n",
      "\u001b[34m[23:47:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[114]#011train-rmse:0.274708#011validation-rmse:0.325083\u001b[0m\n",
      "\u001b[34m[23:48:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[115]#011train-rmse:0.274285#011validation-rmse:0.324807\u001b[0m\n",
      "\u001b[34m[23:48:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[116]#011train-rmse:0.27367#011validation-rmse:0.32438\u001b[0m\n",
      "\u001b[34m[23:48:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[117]#011train-rmse:0.273024#011validation-rmse:0.324119\u001b[0m\n",
      "\u001b[34m[23:48:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[118]#011train-rmse:0.272591#011validation-rmse:0.323847\u001b[0m\n",
      "\u001b[34m[23:48:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[119]#011train-rmse:0.272081#011validation-rmse:0.32366\u001b[0m\n",
      "\u001b[34m[23:48:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[120]#011train-rmse:0.271442#011validation-rmse:0.323563\u001b[0m\n",
      "\u001b[34m[23:48:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[121]#011train-rmse:0.271071#011validation-rmse:0.323314\u001b[0m\n",
      "\u001b[34m[23:48:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[122]#011train-rmse:0.270506#011validation-rmse:0.323164\u001b[0m\n",
      "\u001b[34m[23:48:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[123]#011train-rmse:0.270118#011validation-rmse:0.322927\u001b[0m\n",
      "\u001b[34m[23:48:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[124]#011train-rmse:0.269655#011validation-rmse:0.322631\u001b[0m\n",
      "\u001b[34m[23:48:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[125]#011train-rmse:0.269197#011validation-rmse:0.322498\u001b[0m\n",
      "\u001b[34m[23:48:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[126]#011train-rmse:0.268965#011validation-rmse:0.322327\u001b[0m\n",
      "\u001b[34m[23:48:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[127]#011train-rmse:0.268483#011validation-rmse:0.322203\u001b[0m\n",
      "\u001b[34m[23:48:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 32 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[128]#011train-rmse:0.267974#011validation-rmse:0.321949\u001b[0m\n",
      "\u001b[34m[23:48:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[129]#011train-rmse:0.267572#011validation-rmse:0.321806\u001b[0m\n",
      "\u001b[34m[23:48:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[130]#011train-rmse:0.267136#011validation-rmse:0.321554\u001b[0m\n",
      "\u001b[34m[23:48:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[131]#011train-rmse:0.266688#011validation-rmse:0.321375\u001b[0m\n",
      "\u001b[34m[23:48:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[132]#011train-rmse:0.266224#011validation-rmse:0.321199\u001b[0m\n",
      "\u001b[34m[23:48:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[133]#011train-rmse:0.265678#011validation-rmse:0.320783\u001b[0m\n",
      "\u001b[34m[23:48:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[134]#011train-rmse:0.265312#011validation-rmse:0.320626\u001b[0m\n",
      "\u001b[34m[23:48:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[135]#011train-rmse:0.264855#011validation-rmse:0.32039\u001b[0m\n",
      "\u001b[34m[23:48:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[136]#011train-rmse:0.264333#011validation-rmse:0.320369\u001b[0m\n",
      "\u001b[34m[23:48:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[137]#011train-rmse:0.263938#011validation-rmse:0.320145\u001b[0m\n",
      "\u001b[34m[23:49:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[138]#011train-rmse:0.263567#011validation-rmse:0.319944\u001b[0m\n",
      "\u001b[34m[23:49:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[139]#011train-rmse:0.262978#011validation-rmse:0.319644\u001b[0m\n",
      "\u001b[34m[23:49:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[140]#011train-rmse:0.262538#011validation-rmse:0.319538\u001b[0m\n",
      "\u001b[34m[23:49:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[141]#011train-rmse:0.262249#011validation-rmse:0.319288\u001b[0m\n",
      "\u001b[34m[23:49:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[142]#011train-rmse:0.261916#011validation-rmse:0.319158\u001b[0m\n",
      "\u001b[34m[23:49:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[143]#011train-rmse:0.261364#011validation-rmse:0.319074\u001b[0m\n",
      "\u001b[34m[23:49:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[144]#011train-rmse:0.260901#011validation-rmse:0.318897\u001b[0m\n",
      "\u001b[34m[23:49:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[145]#011train-rmse:0.260514#011validation-rmse:0.318771\u001b[0m\n",
      "\u001b[34m[23:49:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[146]#011train-rmse:0.260178#011validation-rmse:0.318665\u001b[0m\n",
      "\u001b[34m[23:49:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[147]#011train-rmse:0.259673#011validation-rmse:0.31867\u001b[0m\n",
      "\u001b[34m[23:49:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[148]#011train-rmse:0.259332#011validation-rmse:0.31848\u001b[0m\n",
      "\u001b[34m[23:49:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[149]#011train-rmse:0.258829#011validation-rmse:0.318296\u001b[0m\n",
      "\u001b[34m[23:49:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[150]#011train-rmse:0.258326#011validation-rmse:0.318128\u001b[0m\n",
      "\u001b[34m[23:49:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[151]#011train-rmse:0.257974#011validation-rmse:0.318014\u001b[0m\n",
      "\u001b[34m[23:49:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[152]#011train-rmse:0.257452#011validation-rmse:0.317801\u001b[0m\n",
      "\u001b[34m[23:49:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[153]#011train-rmse:0.257076#011validation-rmse:0.31766\u001b[0m\n",
      "\u001b[34m[23:49:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[154]#011train-rmse:0.256653#011validation-rmse:0.317444\u001b[0m\n",
      "\u001b[34m[23:49:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[155]#011train-rmse:0.256218#011validation-rmse:0.317239\u001b[0m\n",
      "\u001b[34m[23:49:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[156]#011train-rmse:0.255704#011validation-rmse:0.31697\u001b[0m\n",
      "\u001b[34m[23:49:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[157]#011train-rmse:0.255343#011validation-rmse:0.316745\u001b[0m\n",
      "\u001b[34m[23:49:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[158]#011train-rmse:0.254972#011validation-rmse:0.316656\u001b[0m\n",
      "\u001b[34m[23:49:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[159]#011train-rmse:0.254466#011validation-rmse:0.316641\u001b[0m\n",
      "\u001b[34m[23:50:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[160]#011train-rmse:0.254177#011validation-rmse:0.316534\u001b[0m\n",
      "\u001b[34m[23:50:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[161]#011train-rmse:0.253641#011validation-rmse:0.316455\u001b[0m\n",
      "\u001b[34m[23:50:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[162]#011train-rmse:0.253161#011validation-rmse:0.316251\u001b[0m\n",
      "\u001b[34m[23:50:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[163]#011train-rmse:0.252759#011validation-rmse:0.316085\u001b[0m\n",
      "\u001b[34m[23:50:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[164]#011train-rmse:0.252411#011validation-rmse:0.31601\u001b[0m\n",
      "\u001b[34m[23:50:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[165]#011train-rmse:0.252034#011validation-rmse:0.315901\u001b[0m\n",
      "\u001b[34m[23:50:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[166]#011train-rmse:0.251746#011validation-rmse:0.315845\u001b[0m\n",
      "\u001b[34m[23:50:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[167]#011train-rmse:0.251358#011validation-rmse:0.315631\u001b[0m\n",
      "\u001b[34m[23:50:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[168]#011train-rmse:0.251068#011validation-rmse:0.3154\u001b[0m\n",
      "\u001b[34m[23:50:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[169]#011train-rmse:0.250806#011validation-rmse:0.315256\u001b[0m\n",
      "\u001b[34m[23:50:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[170]#011train-rmse:0.250497#011validation-rmse:0.315142\u001b[0m\n",
      "\u001b[34m[23:50:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[171]#011train-rmse:0.250175#011validation-rmse:0.315037\u001b[0m\n",
      "\u001b[34m[23:50:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[172]#011train-rmse:0.249849#011validation-rmse:0.314794\u001b[0m\n",
      "\u001b[34m[23:50:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[173]#011train-rmse:0.249526#011validation-rmse:0.314738\u001b[0m\n",
      "\u001b[34m[23:50:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[174]#011train-rmse:0.249055#011validation-rmse:0.314569\u001b[0m\n",
      "\u001b[34m[23:50:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[175]#011train-rmse:0.248645#011validation-rmse:0.314468\u001b[0m\n",
      "\u001b[34m[23:50:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[176]#011train-rmse:0.248281#011validation-rmse:0.314313\u001b[0m\n",
      "\u001b[34m[23:50:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[177]#011train-rmse:0.247905#011validation-rmse:0.314121\u001b[0m\n",
      "\u001b[34m[23:50:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[178]#011train-rmse:0.247343#011validation-rmse:0.313909\u001b[0m\n",
      "\u001b[34m[23:50:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[179]#011train-rmse:0.247011#011validation-rmse:0.313851\u001b[0m\n",
      "\u001b[34m[23:50:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[180]#011train-rmse:0.246701#011validation-rmse:0.313699\u001b[0m\n",
      "\u001b[34m[23:50:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[181]#011train-rmse:0.246151#011validation-rmse:0.313634\u001b[0m\n",
      "\u001b[34m[23:50:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[182]#011train-rmse:0.245697#011validation-rmse:0.313509\u001b[0m\n",
      "\u001b[34m[23:51:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[183]#011train-rmse:0.245184#011validation-rmse:0.313303\u001b[0m\n",
      "\u001b[34m[23:51:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[184]#011train-rmse:0.244844#011validation-rmse:0.31314\u001b[0m\n",
      "\u001b[34m[23:51:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[185]#011train-rmse:0.244529#011validation-rmse:0.312943\u001b[0m\n",
      "\u001b[34m[23:51:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[186]#011train-rmse:0.244274#011validation-rmse:0.312776\u001b[0m\n",
      "\u001b[34m[23:51:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[187]#011train-rmse:0.244027#011validation-rmse:0.312602\u001b[0m\n",
      "\u001b[34m[23:51:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 30 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[188]#011train-rmse:0.243666#011validation-rmse:0.312535\u001b[0m\n",
      "\u001b[34m[23:51:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[189]#011train-rmse:0.243416#011validation-rmse:0.312382\u001b[0m\n",
      "\u001b[34m[23:51:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[190]#011train-rmse:0.243103#011validation-rmse:0.3124\u001b[0m\n",
      "\u001b[34m[23:51:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 2 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[191]#011train-rmse:0.2428#011validation-rmse:0.312358\u001b[0m\n",
      "\u001b[34m[23:51:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[192]#011train-rmse:0.242318#011validation-rmse:0.312324\u001b[0m\n",
      "\u001b[34m[23:51:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[193]#011train-rmse:0.2419#011validation-rmse:0.312346\u001b[0m\n",
      "\u001b[34m[23:51:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[194]#011train-rmse:0.241642#011validation-rmse:0.312204\u001b[0m\n",
      "\u001b[34m[23:51:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[195]#011train-rmse:0.241349#011validation-rmse:0.312056\u001b[0m\n",
      "\u001b[34m[23:51:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[196]#011train-rmse:0.241122#011validation-rmse:0.311888\u001b[0m\n",
      "\u001b[34m[23:51:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[197]#011train-rmse:0.240735#011validation-rmse:0.311685\u001b[0m\n",
      "\u001b[34m[23:51:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[198]#011train-rmse:0.240537#011validation-rmse:0.31159\u001b[0m\n",
      "\u001b[34m[23:51:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[199]#011train-rmse:0.240273#011validation-rmse:0.311537\u001b[0m\n",
      "\u001b[34m[23:51:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[200]#011train-rmse:0.240069#011validation-rmse:0.311413\u001b[0m\n",
      "\u001b[34m[23:51:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[201]#011train-rmse:0.239759#011validation-rmse:0.311269\u001b[0m\n",
      "\u001b[34m[23:51:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[202]#011train-rmse:0.2394#011validation-rmse:0.311243\u001b[0m\n",
      "\u001b[34m[23:51:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[203]#011train-rmse:0.239133#011validation-rmse:0.311066\u001b[0m\n",
      "\u001b[34m[23:51:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[204]#011train-rmse:0.238857#011validation-rmse:0.310903\u001b[0m\n",
      "\u001b[34m[23:52:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[205]#011train-rmse:0.238515#011validation-rmse:0.310776\u001b[0m\n",
      "\u001b[34m[23:52:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[206]#011train-rmse:0.238191#011validation-rmse:0.310743\u001b[0m\n",
      "\u001b[34m[23:52:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[207]#011train-rmse:0.23792#011validation-rmse:0.310596\u001b[0m\n",
      "\u001b[34m[23:52:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[208]#011train-rmse:0.237708#011validation-rmse:0.31056\u001b[0m\n",
      "\u001b[34m[23:52:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[209]#011train-rmse:0.237454#011validation-rmse:0.31047\u001b[0m\n",
      "\u001b[34m[23:52:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[210]#011train-rmse:0.237183#011validation-rmse:0.310444\u001b[0m\n",
      "\u001b[34m[23:52:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[211]#011train-rmse:0.236983#011validation-rmse:0.310339\u001b[0m\n",
      "\u001b[34m[23:52:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[212]#011train-rmse:0.236586#011validation-rmse:0.310305\u001b[0m\n",
      "\u001b[34m[23:52:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[213]#011train-rmse:0.236405#011validation-rmse:0.310293\u001b[0m\n",
      "\u001b[34m[23:52:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[214]#011train-rmse:0.236192#011validation-rmse:0.310241\u001b[0m\n",
      "\u001b[34m[23:52:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[215]#011train-rmse:0.23578#011validation-rmse:0.310023\u001b[0m\n",
      "\u001b[34m[23:52:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[216]#011train-rmse:0.235283#011validation-rmse:0.309838\u001b[0m\n",
      "\u001b[34m[23:52:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[217]#011train-rmse:0.234873#011validation-rmse:0.30969\u001b[0m\n",
      "\u001b[34m[23:52:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[218]#011train-rmse:0.234578#011validation-rmse:0.309622\u001b[0m\n",
      "\u001b[34m[23:52:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[219]#011train-rmse:0.234187#011validation-rmse:0.309554\u001b[0m\n",
      "\u001b[34m[23:52:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[220]#011train-rmse:0.233855#011validation-rmse:0.309559\u001b[0m\n",
      "\u001b[34m[23:52:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[221]#011train-rmse:0.23358#011validation-rmse:0.309522\u001b[0m\n",
      "\u001b[34m[23:52:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[222]#011train-rmse:0.233169#011validation-rmse:0.309513\u001b[0m\n",
      "\u001b[34m[23:52:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[223]#011train-rmse:0.2329#011validation-rmse:0.309459\u001b[0m\n",
      "\u001b[34m[23:52:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[224]#011train-rmse:0.232634#011validation-rmse:0.309424\u001b[0m\n",
      "\u001b[34m[23:52:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[225]#011train-rmse:0.232226#011validation-rmse:0.309256\u001b[0m\n",
      "\u001b[34m[23:52:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[226]#011train-rmse:0.231932#011validation-rmse:0.309075\u001b[0m\n",
      "\u001b[34m[23:52:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[227]#011train-rmse:0.231581#011validation-rmse:0.308905\u001b[0m\n",
      "\u001b[34m[23:53:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[228]#011train-rmse:0.231423#011validation-rmse:0.308804\u001b[0m\n",
      "\u001b[34m[23:53:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[229]#011train-rmse:0.231056#011validation-rmse:0.308717\u001b[0m\n",
      "\u001b[34m[23:53:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[230]#011train-rmse:0.230807#011validation-rmse:0.308571\u001b[0m\n",
      "\u001b[34m[23:53:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[231]#011train-rmse:0.230618#011validation-rmse:0.308548\u001b[0m\n",
      "\u001b[34m[23:53:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[232]#011train-rmse:0.230307#011validation-rmse:0.308511\u001b[0m\n",
      "\u001b[34m[23:53:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[233]#011train-rmse:0.230034#011validation-rmse:0.3085\u001b[0m\n",
      "\u001b[34m[23:53:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[234]#011train-rmse:0.229739#011validation-rmse:0.308492\u001b[0m\n",
      "\u001b[34m[23:53:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[235]#011train-rmse:0.22925#011validation-rmse:0.308401\u001b[0m\n",
      "\u001b[34m[23:53:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[236]#011train-rmse:0.228909#011validation-rmse:0.308442\u001b[0m\n",
      "\u001b[34m[23:53:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[237]#011train-rmse:0.228558#011validation-rmse:0.30836\u001b[0m\n",
      "\u001b[34m[23:53:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[238]#011train-rmse:0.228374#011validation-rmse:0.308397\u001b[0m\n",
      "\u001b[34m[23:53:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[239]#011train-rmse:0.227952#011validation-rmse:0.308393\u001b[0m\n",
      "\u001b[34m[23:53:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[240]#011train-rmse:0.227679#011validation-rmse:0.308323\u001b[0m\n",
      "\u001b[34m[23:53:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[241]#011train-rmse:0.227222#011validation-rmse:0.308123\u001b[0m\n",
      "\u001b[34m[23:53:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[242]#011train-rmse:0.227025#011validation-rmse:0.308057\u001b[0m\n",
      "\u001b[34m[23:53:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[243]#011train-rmse:0.226637#011validation-rmse:0.30795\u001b[0m\n",
      "\u001b[34m[23:53:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 2 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[244]#011train-rmse:0.226443#011validation-rmse:0.307865\u001b[0m\n",
      "\u001b[34m[23:53:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[245]#011train-rmse:0.226097#011validation-rmse:0.30783\u001b[0m\n",
      "\u001b[34m[23:53:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[246]#011train-rmse:0.225773#011validation-rmse:0.307752\u001b[0m\n",
      "\u001b[34m[23:53:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[247]#011train-rmse:0.225583#011validation-rmse:0.307646\u001b[0m\n",
      "\u001b[34m[23:53:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[248]#011train-rmse:0.225226#011validation-rmse:0.30754\u001b[0m\n",
      "\u001b[34m[23:53:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[249]#011train-rmse:0.225006#011validation-rmse:0.307472\u001b[0m\n",
      "\u001b[34m[23:54:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[250]#011train-rmse:0.224746#011validation-rmse:0.307436\u001b[0m\n",
      "\u001b[34m[23:54:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[251]#011train-rmse:0.224478#011validation-rmse:0.307387\u001b[0m\n",
      "\u001b[34m[23:54:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[252]#011train-rmse:0.224302#011validation-rmse:0.307344\u001b[0m\n",
      "\u001b[34m[23:54:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[253]#011train-rmse:0.224176#011validation-rmse:0.30729\u001b[0m\n",
      "\u001b[34m[23:54:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[254]#011train-rmse:0.224037#011validation-rmse:0.307268\u001b[0m\n",
      "\u001b[34m[23:54:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[255]#011train-rmse:0.223902#011validation-rmse:0.307249\u001b[0m\n",
      "\u001b[34m[23:54:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[256]#011train-rmse:0.223621#011validation-rmse:0.307125\u001b[0m\n",
      "\u001b[34m[23:54:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[257]#011train-rmse:0.222953#011validation-rmse:0.307059\u001b[0m\n",
      "\u001b[34m[23:54:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[258]#011train-rmse:0.222808#011validation-rmse:0.306943\u001b[0m\n",
      "\u001b[34m[23:54:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[259]#011train-rmse:0.222581#011validation-rmse:0.306823\u001b[0m\n",
      "\u001b[34m[23:54:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 2 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[260]#011train-rmse:0.22237#011validation-rmse:0.30675\u001b[0m\n",
      "\u001b[34m[23:54:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[261]#011train-rmse:0.222024#011validation-rmse:0.306681\u001b[0m\n",
      "\u001b[34m[23:54:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[262]#011train-rmse:0.221761#011validation-rmse:0.306669\u001b[0m\n",
      "\u001b[34m[23:54:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[263]#011train-rmse:0.221658#011validation-rmse:0.306645\u001b[0m\n",
      "\u001b[34m[23:54:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[264]#011train-rmse:0.221418#011validation-rmse:0.30652\u001b[0m\n",
      "\u001b[34m[23:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[265]#011train-rmse:0.22127#011validation-rmse:0.306464\u001b[0m\n",
      "\u001b[34m[23:54:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[266]#011train-rmse:0.221077#011validation-rmse:0.306438\u001b[0m\n",
      "\u001b[34m[23:54:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[267]#011train-rmse:0.220924#011validation-rmse:0.306443\u001b[0m\n",
      "\u001b[34m[23:54:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[268]#011train-rmse:0.220815#011validation-rmse:0.306353\u001b[0m\n",
      "\u001b[34m[23:54:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[269]#011train-rmse:0.220672#011validation-rmse:0.306323\u001b[0m\n",
      "\u001b[34m[23:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[270]#011train-rmse:0.220335#011validation-rmse:0.306227\u001b[0m\n",
      "\u001b[34m[23:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[271]#011train-rmse:0.220056#011validation-rmse:0.30609\u001b[0m\n",
      "\u001b[34m[23:54:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[272]#011train-rmse:0.219952#011validation-rmse:0.306031\u001b[0m\n",
      "\u001b[34m[23:55:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[273]#011train-rmse:0.219714#011validation-rmse:0.30596\u001b[0m\n",
      "\u001b[34m[23:55:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[274]#011train-rmse:0.219324#011validation-rmse:0.305974\u001b[0m\n",
      "\u001b[34m[23:55:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[275]#011train-rmse:0.218984#011validation-rmse:0.30592\u001b[0m\n",
      "\u001b[34m[23:55:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[276]#011train-rmse:0.218826#011validation-rmse:0.305871\u001b[0m\n",
      "\u001b[34m[23:55:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[277]#011train-rmse:0.21862#011validation-rmse:0.305774\u001b[0m\n",
      "\u001b[34m[23:55:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[278]#011train-rmse:0.218478#011validation-rmse:0.305723\u001b[0m\n",
      "\u001b[34m[23:55:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[279]#011train-rmse:0.21838#011validation-rmse:0.305665\u001b[0m\n",
      "\u001b[34m[23:55:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 2 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[280]#011train-rmse:0.218148#011validation-rmse:0.305633\u001b[0m\n",
      "\u001b[34m[23:55:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[281]#011train-rmse:0.217901#011validation-rmse:0.305535\u001b[0m\n",
      "\u001b[34m[23:55:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[282]#011train-rmse:0.217723#011validation-rmse:0.305471\u001b[0m\n",
      "\u001b[34m[23:55:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[283]#011train-rmse:0.217434#011validation-rmse:0.305365\u001b[0m\n",
      "\u001b[34m[23:55:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[284]#011train-rmse:0.21723#011validation-rmse:0.305271\u001b[0m\n",
      "\u001b[34m[23:55:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[285]#011train-rmse:0.217028#011validation-rmse:0.305248\u001b[0m\n",
      "\u001b[34m[23:55:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[286]#011train-rmse:0.216581#011validation-rmse:0.305257\u001b[0m\n",
      "\u001b[34m[23:55:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[287]#011train-rmse:0.216344#011validation-rmse:0.305214\u001b[0m\n",
      "\u001b[34m[23:55:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[288]#011train-rmse:0.21617#011validation-rmse:0.305189\u001b[0m\n",
      "\u001b[34m[23:55:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[289]#011train-rmse:0.215722#011validation-rmse:0.305041\u001b[0m\n",
      "\u001b[34m[23:55:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[290]#011train-rmse:0.215616#011validation-rmse:0.305066\u001b[0m\n",
      "\u001b[34m[23:55:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[291]#011train-rmse:0.215334#011validation-rmse:0.305068\u001b[0m\n",
      "\u001b[34m[23:55:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[292]#011train-rmse:0.215044#011validation-rmse:0.305025\u001b[0m\n",
      "\u001b[34m[23:55:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[293]#011train-rmse:0.214636#011validation-rmse:0.305101\u001b[0m\n",
      "\u001b[34m[23:55:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[294]#011train-rmse:0.214464#011validation-rmse:0.305048\u001b[0m\n",
      "\u001b[34m[23:55:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[295]#011train-rmse:0.214218#011validation-rmse:0.304923\u001b[0m\n",
      "\u001b[34m[23:56:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[296]#011train-rmse:0.21399#011validation-rmse:0.30494\u001b[0m\n",
      "\u001b[34m[23:56:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 2 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[297]#011train-rmse:0.2138#011validation-rmse:0.304885\u001b[0m\n",
      "\u001b[34m[23:56:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[298]#011train-rmse:0.2136#011validation-rmse:0.304919\u001b[0m\n",
      "\u001b[34m[23:56:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[299]#011train-rmse:0.213464#011validation-rmse:0.304906\u001b[0m\n",
      "\u001b[34m[23:56:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[300]#011train-rmse:0.213292#011validation-rmse:0.304859\u001b[0m\n",
      "\u001b[34m[23:56:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[301]#011train-rmse:0.213145#011validation-rmse:0.304778\u001b[0m\n",
      "\u001b[34m[23:56:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[302]#011train-rmse:0.212988#011validation-rmse:0.304766\u001b[0m\n",
      "\u001b[34m[23:56:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[303]#011train-rmse:0.212846#011validation-rmse:0.304717\u001b[0m\n",
      "\u001b[34m[23:56:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[304]#011train-rmse:0.212662#011validation-rmse:0.304709\u001b[0m\n",
      "\u001b[34m[23:56:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[305]#011train-rmse:0.212382#011validation-rmse:0.304721\u001b[0m\n",
      "\u001b[34m[23:56:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[306]#011train-rmse:0.212166#011validation-rmse:0.304683\u001b[0m\n",
      "\u001b[34m[23:56:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[307]#011train-rmse:0.211969#011validation-rmse:0.304729\u001b[0m\n",
      "\u001b[34m[23:56:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[308]#011train-rmse:0.211638#011validation-rmse:0.304666\u001b[0m\n",
      "\u001b[34m[23:56:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[309]#011train-rmse:0.211385#011validation-rmse:0.304585\u001b[0m\n",
      "\u001b[34m[23:56:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[310]#011train-rmse:0.211205#011validation-rmse:0.304582\u001b[0m\n",
      "\u001b[34m[23:56:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[311]#011train-rmse:0.211046#011validation-rmse:0.304525\u001b[0m\n",
      "\u001b[34m[23:56:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[312]#011train-rmse:0.210938#011validation-rmse:0.304483\u001b[0m\n",
      "\u001b[34m[23:56:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[313]#011train-rmse:0.210813#011validation-rmse:0.304419\u001b[0m\n",
      "\u001b[34m[23:56:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[314]#011train-rmse:0.210603#011validation-rmse:0.304349\u001b[0m\n",
      "\u001b[34m[23:56:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[315]#011train-rmse:0.210381#011validation-rmse:0.304356\u001b[0m\n",
      "\u001b[34m[23:56:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[316]#011train-rmse:0.210164#011validation-rmse:0.304342\u001b[0m\n",
      "\u001b[34m[23:56:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[317]#011train-rmse:0.209997#011validation-rmse:0.304296\u001b[0m\n",
      "\u001b[34m[23:57:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[318]#011train-rmse:0.209726#011validation-rmse:0.304127\u001b[0m\n",
      "\u001b[34m[23:57:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[319]#011train-rmse:0.209544#011validation-rmse:0.304056\u001b[0m\n",
      "\u001b[34m[23:57:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[320]#011train-rmse:0.209194#011validation-rmse:0.303866\u001b[0m\n",
      "\u001b[34m[23:57:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[321]#011train-rmse:0.208836#011validation-rmse:0.30377\u001b[0m\n",
      "\u001b[34m[23:57:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 32 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[322]#011train-rmse:0.208665#011validation-rmse:0.303788\u001b[0m\n",
      "\u001b[34m[23:57:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[323]#011train-rmse:0.20836#011validation-rmse:0.303708\u001b[0m\n",
      "\u001b[34m[23:57:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[324]#011train-rmse:0.208003#011validation-rmse:0.303738\u001b[0m\n",
      "\u001b[34m[23:57:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[325]#011train-rmse:0.207888#011validation-rmse:0.303697\u001b[0m\n",
      "\u001b[34m[23:57:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[326]#011train-rmse:0.207784#011validation-rmse:0.303655\u001b[0m\n",
      "\u001b[34m[23:57:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[327]#011train-rmse:0.207655#011validation-rmse:0.303635\u001b[0m\n",
      "\u001b[34m[23:57:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[328]#011train-rmse:0.207361#011validation-rmse:0.303584\u001b[0m\n",
      "\u001b[34m[23:57:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[329]#011train-rmse:0.20703#011validation-rmse:0.303568\u001b[0m\n",
      "\u001b[34m[23:57:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[330]#011train-rmse:0.206867#011validation-rmse:0.30349\u001b[0m\n",
      "\u001b[34m[23:57:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[331]#011train-rmse:0.206756#011validation-rmse:0.303406\u001b[0m\n",
      "\u001b[34m[23:57:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[332]#011train-rmse:0.206564#011validation-rmse:0.303342\u001b[0m\n",
      "\u001b[34m[23:57:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[333]#011train-rmse:0.206401#011validation-rmse:0.303254\u001b[0m\n",
      "\u001b[34m[23:57:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[334]#011train-rmse:0.206311#011validation-rmse:0.303291\u001b[0m\n",
      "\u001b[34m[23:57:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[335]#011train-rmse:0.205903#011validation-rmse:0.303243\u001b[0m\n",
      "\u001b[34m[23:57:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[336]#011train-rmse:0.20576#011validation-rmse:0.303179\u001b[0m\n",
      "\u001b[34m[23:57:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[337]#011train-rmse:0.205625#011validation-rmse:0.30314\u001b[0m\n",
      "\u001b[34m[23:57:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 26 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[338]#011train-rmse:0.205423#011validation-rmse:0.303099\u001b[0m\n",
      "\u001b[34m[23:57:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[339]#011train-rmse:0.205215#011validation-rmse:0.30311\u001b[0m\n",
      "\u001b[34m[23:58:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[340]#011train-rmse:0.205112#011validation-rmse:0.303133\u001b[0m\n",
      "\u001b[34m[23:58:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[341]#011train-rmse:0.204984#011validation-rmse:0.303161\u001b[0m\n",
      "\u001b[34m[23:58:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 2 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[342]#011train-rmse:0.20485#011validation-rmse:0.303114\u001b[0m\n",
      "\u001b[34m[23:58:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[343]#011train-rmse:0.204714#011validation-rmse:0.303069\u001b[0m\n",
      "\u001b[34m[23:58:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 28 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[344]#011train-rmse:0.204355#011validation-rmse:0.302982\u001b[0m\n",
      "\u001b[34m[23:58:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[345]#011train-rmse:0.204275#011validation-rmse:0.302949\u001b[0m\n",
      "\u001b[34m[23:58:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[346]#011train-rmse:0.204081#011validation-rmse:0.302909\u001b[0m\n",
      "\u001b[34m[23:58:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[347]#011train-rmse:0.20392#011validation-rmse:0.302844\u001b[0m\n",
      "\u001b[34m[23:58:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[348]#011train-rmse:0.203657#011validation-rmse:0.302782\u001b[0m\n",
      "\u001b[34m[23:58:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[349]#011train-rmse:0.203479#011validation-rmse:0.302759\u001b[0m\n",
      "\u001b[34m[23:58:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[350]#011train-rmse:0.203336#011validation-rmse:0.302782\u001b[0m\n",
      "\u001b[34m[23:58:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[351]#011train-rmse:0.203229#011validation-rmse:0.302765\u001b[0m\n",
      "\u001b[34m[23:58:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[352]#011train-rmse:0.203096#011validation-rmse:0.302758\u001b[0m\n",
      "\u001b[34m[23:58:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[353]#011train-rmse:0.202929#011validation-rmse:0.302679\u001b[0m\n",
      "\u001b[34m[23:58:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[354]#011train-rmse:0.202825#011validation-rmse:0.30259\u001b[0m\n",
      "\u001b[34m[23:58:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[355]#011train-rmse:0.202656#011validation-rmse:0.302608\u001b[0m\n",
      "\u001b[34m[23:58:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[356]#011train-rmse:0.202538#011validation-rmse:0.302558\u001b[0m\n",
      "\u001b[34m[23:58:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[357]#011train-rmse:0.202479#011validation-rmse:0.30248\u001b[0m\n",
      "\u001b[34m[23:58:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 22 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[358]#011train-rmse:0.202199#011validation-rmse:0.302418\u001b[0m\n",
      "\u001b[34m[23:58:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[359]#011train-rmse:0.202031#011validation-rmse:0.302384\u001b[0m\n",
      "\u001b[34m[23:58:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[360]#011train-rmse:0.201923#011validation-rmse:0.30227\u001b[0m\n",
      "\u001b[34m[23:58:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[361]#011train-rmse:0.201746#011validation-rmse:0.30225\u001b[0m\n",
      "\u001b[34m[23:58:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[362]#011train-rmse:0.201573#011validation-rmse:0.302197\u001b[0m\n",
      "\u001b[34m[23:59:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[363]#011train-rmse:0.201438#011validation-rmse:0.302156\u001b[0m\n",
      "\u001b[34m[23:59:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 32 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[364]#011train-rmse:0.201313#011validation-rmse:0.302083\u001b[0m\n",
      "\u001b[34m[23:59:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[365]#011train-rmse:0.201204#011validation-rmse:0.302094\u001b[0m\n",
      "\u001b[34m[23:59:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[366]#011train-rmse:0.201071#011validation-rmse:0.302056\u001b[0m\n",
      "\u001b[34m[23:59:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[367]#011train-rmse:0.200911#011validation-rmse:0.302127\u001b[0m\n",
      "\u001b[34m[23:59:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[368]#011train-rmse:0.200637#011validation-rmse:0.302108\u001b[0m\n",
      "\u001b[34m[23:59:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[369]#011train-rmse:0.200447#011validation-rmse:0.302038\u001b[0m\n",
      "\u001b[34m[23:59:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 12 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[370]#011train-rmse:0.200214#011validation-rmse:0.302072\u001b[0m\n",
      "\u001b[34m[23:59:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[371]#011train-rmse:0.199889#011validation-rmse:0.302093\u001b[0m\n",
      "\u001b[34m[23:59:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[372]#011train-rmse:0.199627#011validation-rmse:0.302137\u001b[0m\n",
      "\u001b[34m[23:59:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 4 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[373]#011train-rmse:0.199467#011validation-rmse:0.302154\u001b[0m\n",
      "\u001b[34m[23:59:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 20 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[374]#011train-rmse:0.199234#011validation-rmse:0.3022\u001b[0m\n",
      "\u001b[34m[23:59:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 6 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[375]#011train-rmse:0.199122#011validation-rmse:0.302179\u001b[0m\n",
      "\u001b[34m[23:59:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 16 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[376]#011train-rmse:0.19899#011validation-rmse:0.302216\u001b[0m\n",
      "\u001b[34m[23:59:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[377]#011train-rmse:0.198877#011validation-rmse:0.302205\u001b[0m\n",
      "\u001b[34m[23:59:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 8 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[378]#011train-rmse:0.19873#011validation-rmse:0.302219\u001b[0m\n",
      "\u001b[34m[23:59:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[379]#011train-rmse:0.198597#011validation-rmse:0.302119\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[369]#011train-rmse:0.200447#011validation-rmse:0.302038\n",
      "\u001b[0m\n",
      "Training seconds: 1069\n",
      "Billable seconds: 1069\n"
     ]
    }
   ],
   "source": [
    "# Let's pick the best model for the performance.\n",
    "xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())    # select best model\n",
    "\n",
    "# Now, the procedure are same as batch_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBq5rqm2JF1X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:Using already existing model: xgboost-200612-2326-006-e60fb90c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-06-13 00:10:40 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-06-13 00:10:40 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-06-13 00:10:40 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-06-13 00:10:40 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-06-13 00:10:40 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-06-13 00:10:40 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-06-13 00:10:40 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:10:40:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:10:40:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:10:40:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:10:40:INFO] Model loaded successfully for worker : 41\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:14:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:14:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:14:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:14:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:14:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:14:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2020-06-13T00:11:11.335:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:15:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:15:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:15:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:15:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:16:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:16:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:16:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:16:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:17:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:17:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:16:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:16:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:16:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:16:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:17:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:17:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:18:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:18:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:18:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:18:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:19:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:19:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:19:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:19:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:22:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:22:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:22:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:23:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:23:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:22:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:22:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:22:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:23:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:23:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:27:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:27:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:27:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:27:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:27:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:28:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:28:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:27:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:28:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:28:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:29:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:29:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m[2020-06-13:00:11:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:37:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:37:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:37:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:37:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-13:00:11:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:37:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:37:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-13:00:11:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb_attached.transformer(instance_count =1, instance_type = 'ml.m4.xlarge')       # used Batch_transform method from sagemaker\n",
    " \n",
    "xgb_transformer.transform(test_location,content_type = 'text/csv',split_type= 'Line')     # read data from test location for predictinog result.\n",
    "\n",
    "xgb_transformer.wait()                                                                     # wait for response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JXzONtjJFy8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 256.0 KiB/372.8 KiB (786.4 KiB/s) with 1 file(s) remaining\r",
      "Completed 372.8 KiB/372.8 KiB (1.1 MiB/s) with 1 file(s) remaining  \r",
      "download: s3://sagemaker-us-west-2-337299574287/xgboost-200612-2326-006-e60fb90c-2020-06-13-00-07-15-230/test.csv.out to ../data/xgboost/test.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir                               # save test result to s3 (for local use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UxHTy9Ox2Ry"
   },
   "outputs": [],
   "source": [
    "# For, accuracy metric calculation. \n",
    "predictions = pd.read_csv(os.path.join(data_dir,'test.csv.out'),header=None)\n",
    "predictions = [round(num) for num in predictions.squeeze().values]              # create list of prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Y_hgNIfx2OR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y,predictions)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k28nwMw96MeJ"
   },
   "source": [
    "Note that this time model give better output than previous notebook, which is 87.28 %, which is 2.16% higher than previous one.(85.12%).\n",
    "\n",
    "---\n",
    "\n",
    "### Clean up disk and dir (free memory for next prediction)\n",
    "\n",
    "The default notebook instance on SageMaker doesn't have a lot of excess disk space available. As you continue to complete and execute other notebooks you will eventually fill up this disk space, leading to errors which can be difficult to diagnose. \n",
    "\n",
    "Once you are completely finished using a notebook it is a good idea to remove the files that you created along the way. Of course, you can do this from the terminal or from the notebook hub if you would like. The cell below contains some commands to clean up the created files from within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQXA_m0mx2Jk"
   },
   "outputs": [],
   "source": [
    "# first delete the files from directory\n",
    "!rm $data_dir/*\n",
    "\n",
    "# delete directory itself\n",
    "!rmdir $data_dir\n",
    "\n",
    "# remove all the files in the cache_dir\n",
    "!rm $cache_dir/*\n",
    "\n",
    "# remove cache_directory itself\n",
    "!rmdir $cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-ye14Eix2GK"
   },
   "outputs": [],
   "source": [
    "# Keep Learning,Enjoy Empowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentimental_Analytics(AWS-SageMaker_BTHT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
