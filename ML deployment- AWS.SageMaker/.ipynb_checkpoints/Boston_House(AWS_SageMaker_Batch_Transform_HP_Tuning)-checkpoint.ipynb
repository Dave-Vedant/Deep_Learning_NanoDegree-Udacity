{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vedantdave77/project.Orca/blob/master/ML%20deployment-%20AWS.SageMaker/Boston_House(AWS_SageMaker_Batch_Transform_HP_Tuning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIWbGtVPjtnQ"
   },
   "source": [
    "# AWS SAGEMAKER \n",
    "Hello, I am [Vedant_Dave](vedantdave77@gmail.com), a inspiratonal Machine Learning Practitiner.\n",
    "## Intro To Topic\n",
    "Today, I am going to deploy Boston Housing data Project using AWS Sagemaker's High level API called - \"Python SDK\". \n",
    "> This API has facility to train and deploy model in cloud directly from innner Jupyter notebook creation. So, I will use simple Machine learning workflow as usaual. \n",
    "\n",
    "> Data loading --> Data Preparation --> Model Training --> HP Tuning --> Deployment in AWS. (Hopefully, try to make Web Application). \n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "First of all, I will use SageMaker's batch transform feature, which  is a high-performance and high-throughput method for transforming data and generating inferences. \n",
    "\n",
    "- I personally think, It's ideal for scenarios where you're dealing with large batches of data, don't need sub-second latency, or need to both preprocess and transform the training data. \n",
    "\n",
    "- My main focus is to deploy model, so on analytic point of view, I tried to use Sagemaker's ML library and find median housing price for specific housing requrements in certain areas. \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB3yDsFIJB_W"
   },
   "source": [
    "## Set Environment (lib & SageMaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gslpcnrwJiMC"
   },
   "outputs": [],
   "source": [
    "# Setting-up Notebook in relevant environment.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOtUDtqJmNcg"
   },
   "outputs": [],
   "source": [
    "# set sagemaker in env.\n",
    "import sagemaker  \n",
    "from sagemaker import get_execution_role                                        # import execution role(IAM type)                                       \n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri                     # instance (s3/sagemaker- uri)\n",
    "from sagemaker.predictor import csv_serializer                                  # to serialize data for prediction purpose\n",
    "\n",
    "# Object to represent current active session of sagemaker - contains some useful info. for future usage.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# object shows IAM role - will help us to assign training job to sagemaker.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gP7UA5RHoG1c"
   },
   "source": [
    "## Download Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGz26OMNoDnN"
   },
   "outputs": [],
   "source": [
    "# The following data will be download from sagemaker's storage. (Actully, boston is one of the ideal dataset for practice purpose.)\n",
    "boston = load_boston()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQ1Ldf2HoXgX"
   },
   "source": [
    "## Data preparation and splitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "E5HXQWXdoDkW",
    "outputId": "0537510b-a48e-4560-d81b-16e64e6edfca"
   },
   "outputs": [],
   "source": [
    "# prepare data for python notebook\n",
    "X_bos_pd = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y_bos_pd = pd.DataFrame(boston.target)\n",
    "\n",
    "# splitting into train and test\n",
    "X_train,X_test,y_train,y_test = sklearn.model_selection.train_test_split(X_bos_pd, y_bos_pd, test_size =0.33)\n",
    "\n",
    "# further splitting of train to train(2/3) and validation(1/3)\n",
    "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X_train, y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9mDXm4qQPo"
   },
   "source": [
    "## Uploading data files to S3.\n",
    "\n",
    "Keep in mind that, \n",
    "\n",
    "- When a training job is constructed using SageMaker, a container is executed which performs the training operation.\n",
    "- This container is given access to data that is stored in S3. This means that we need to upload the data we want to use for training to S3. \n",
    "- In addition, when we perform a batch transform job, SageMaker expects the input data to be stored on S3. We can use the SageMaker API to do this and hide some of the details, but first data saved locally and then uploaded to S3 container.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yc2SI2v4xy92"
   },
   "outputs": [],
   "source": [
    "# define & ensure data dictionary...\n",
    "data_dir = '.../data/boston'\n",
    "if not os.path.exists(data_dir):\n",
    "  os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYQAaia5oDiK"
   },
   "outputs": [],
   "source": [
    "# In data_dir, I amd creating csv file format for all data, and in validation and train set target data comes in first columns.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir,'test.csv'),header = False, index = False)\n",
    " \n",
    "pd.concat([y_val,X_val], axis =1).to_csv(os.path.join(data_dir, 'validation.csv'),header=False, index= False)\n",
    "pd.concat([y_train,X_train],axis =1).to_csv(os.path.join(data_dir,'train.csv'),header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4w9BxAIs13oi"
   },
   "source": [
    "### Upload to S3 - data storage.\n",
    "Its good prectice to give prefix to your S3 bucket, so you can easily get idea about specific container for relevant project. \n",
    "- Here, I am giving name as \"dataset_name-algorithm_name-API_level\".\n",
    "\n",
    "I will use xgboost algorithm, which is one of the modern approach for supervised learning. It boost our algorithm gradient and give high accuracy result with good F1 score Matrix. \n",
    "\n",
    "> For more info, visit [XGBoost](https://xgboost.readthedocs.io/en/latest/) official documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rq5Uhd5doDel"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "prefix = 'boston-xgboost-HL'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir,'test.csv'),key_prefix = prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir,'validation.csv'), key_prefix = prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir,'train.csv'),key_prefix = prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pXKWD1V_36wO"
   },
   "source": [
    "## Training XGBoost Model\n",
    "There are two options for training model either use high-level API in which Sage-Maker will train algorithm ownself or from low level API inwhich we need to define our own work. \n",
    "\n",
    "I will go with both the cases to represent difference. Before this we must need some important information for sagemaker to give permissions and you can find them from [common_para_list](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXtdSvnHoDa3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.amazon.amazon_estimator:'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n",
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# define container with uri to define container with session and ml-model info.\n",
    "container = get_image_uri(session.boto_region_name,'xgboost')\n",
    "\n",
    "# Now construct container object with requried parametrs.\n",
    "xgb = sagemaker.estimator.Estimator(container,                                  # our training container\n",
    "                                    role,                                       # defined IAM role for training\n",
    "                                    train_instance_count=1,                     # instaces, depend how many you created - for lengthy job need more\n",
    "                                    train_instance_type = 'ml.m4.xlarge',       # type of instace type for deployjent - can use m2 to m5 (AWS rate will according to that, check here --> https://aws.amazon.com/sagemaker/pricing/)\n",
    "                                    output_path = 's3://{}/{}/output'.format(session.default_bucket(),prefix),   # output destination\n",
    "                                    sagemaker_session=session)                  # current session (because instance are on regionwise servers, s3 bucket is globalize platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjnFyDbzCRO9"
   },
   "source": [
    "> ***SageMaker has xgb Hyper parameters for tuning so, we can seperate parameters in two main clubs first one are static and other will be dynamic(continuouse) tuing paraeters. you can check the documentation here clck it*** [here.](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8uFTgAYkoDYW"
   },
   "outputs": [],
   "source": [
    "# set HyperParameter of model.\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',        # ()':' for represents)\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3aRkAIhvL9Yk"
   },
   "source": [
    "The best thing about AWS service is about Hyper Parameter tuning freatures. \n",
    "> If you have little bit experience with ML and DL deep network training on complex data then you know, How much frustrating to set HP for better model accuracy, we all face different problems for that such as overfitting, gradient explodation/ vanishing, underfitting, time/computation complexity etc...\n",
    "\n",
    "With HP tuner we can provide range for output and wait for best model HP, sagemaker will return the best executed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bojDn-F5L8lP"
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb,                                    # choose your model type (ML-approach)\n",
    "                                               objective_metric_name = 'validation:rmse',          # Evaluation Matrix for model comparison \n",
    "                                               objective_type = 'Minimize',                        # What you want? ---> minimize / maximize matrix result as best model (here, minimize will give best accuracy (due to error matrix))\n",
    "                                               max_jobs = 20,                                      # total models to train --> More model=>more time=> expensive \n",
    "                                               max_parallel_jobs = 3,                              # The number of models to train in parallel, (more parallel operation--> powerful instance type(cpu) => More Money to spend)\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),        # visit -->  https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5), \n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHH4FRGZoDVs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# give some more info to sagemaker about our input's data structure and arrangement\n",
    "s3_input_train = sagemaker.s3_input(s3_data= train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data= val_location, content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train':s3_input_train,'validation': s3_input_validation})      ##### check the model name during fit (bug fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM8hxoBOMAr6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# wait for model response (after all, we gave 20 model execution job!)\n",
    "xgb_hyperparameter_tuner.wait()                                                     ##### model job conflication occured -> solved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZuFagfPMAO4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost-200606-0559-019-e996df8f'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pick best model for me for highest accuracy\n",
    "xgb_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJfG2n5QL_q5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 06:23:19 Starting - Preparing the instances for training\n",
      "2020-06-06 06:23:19 Downloading - Downloading input data\n",
      "2020-06-06 06:23:19 Training - Training image download completed. Training in progress.\n",
      "2020-06-06 06:23:19 Uploading - Uploading generated training model\n",
      "2020-06-06 06:23:19 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:23:08:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:23:08:INFO] Setting up HPO optimized metric to be : rmse\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:23:08:INFO] File size need to be processed in the node: 0.02mb. Available memory size in the node: 8478.66mb\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:23:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:23:08] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[06:23:08] 227x13 matrix with 2951 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:23:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:23:08] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[06:23:08] 112x13 matrix with 1456 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:15.6539#011validation-rmse:15.736\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:10.5926#011validation-rmse:10.8719\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 6 pruned nodes, max_depth=7\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:7.22896#011validation-rmse:7.60705\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 12 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:5.15337#011validation-rmse:5.66068\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 14 pruned nodes, max_depth=12\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:3.88283#011validation-rmse:4.70976\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 48 pruned nodes, max_depth=11\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:3.21715#011validation-rmse:4.28596\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 48 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:2.58836#011validation-rmse:3.87494\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 46 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:2.17329#011validation-rmse:3.70967\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 56 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:1.76402#011validation-rmse:3.49707\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 72 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:1.57619#011validation-rmse:3.38433\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 46 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:1.37533#011validation-rmse:3.32353\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 62 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:1.28341#011validation-rmse:3.31532\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 56 pruned nodes, max_depth=8\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:1.22622#011validation-rmse:3.32767\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 84 pruned nodes, max_depth=7\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:1.17947#011validation-rmse:3.2889\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 94 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:1.15711#011validation-rmse:3.28853\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 86 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:1.09337#011validation-rmse:3.33183\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 68 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:1.07607#011validation-rmse:3.33838\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 92 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:1.03424#011validation-rmse:3.31897\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 96 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.990003#011validation-rmse:3.32086\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 82 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.990813#011validation-rmse:3.32824\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 100 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.972074#011validation-rmse:3.31316\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 84 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.952092#011validation-rmse:3.28104\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 88 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.935609#011validation-rmse:3.27909\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 94 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.91811#011validation-rmse:3.30961\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 100 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.917991#011validation-rmse:3.31005\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 102 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.910708#011validation-rmse:3.30772\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 110 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.911181#011validation-rmse:3.30636\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 72 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.893858#011validation-rmse:3.30774\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 92 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.893849#011validation-rmse:3.30756\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 100 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.893995#011validation-rmse:3.30882\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 106 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.893883#011validation-rmse:3.30805\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 104 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.894303#011validation-rmse:3.31003\u001b[0m\n",
      "\u001b[34m[06:23:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 100 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.894094#011validation-rmse:3.30928\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.935609#011validation-rmse:3.27909\n",
      "\u001b[0m\n",
      "Training seconds: 67\n",
      "Billable seconds: 67\n"
     ]
    }
   ],
   "source": [
    "# replace our previous xgb with best one.\n",
    "xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fr_EtAQUDXrM"
   },
   "source": [
    "## Test Model\n",
    "Testing need special requirement of sagemaker-batch transform. It works in background so we need to wait.\n",
    "\n",
    "So, first let's construct transform object and give batch transform work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeUMCepHoDT0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb_attached.transformer(instance_count =1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxfJWfd1oDQs"
   },
   "outputs": [],
   "source": [
    "xgb_transformer.transform(test_location,content_type='text/csv',split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJXJx29AoDCQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-06-06 06:26:56 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-06-06 06:26:56 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-06-06 06:26:56 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-06-06 06:26:56 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-06-06 06:26:56 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:26:56:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:26:56:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-06-06 06:26:56 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-06-06 06:26:56 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:26:56:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:26:56:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:27:21:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-06-06:06:27:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-06-06:06:27:21:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-06-06:06:27:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2020-06-06T06:27:21.522:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QV0QZe-oFdZG"
   },
   "source": [
    "Our Output will saved automatically, For more operation we need to download it locally (locally means on the notebook instance, not on local drive!)....this will doen by jupyter notebook magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72YF0ABXFTVU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2.3 KiB/2.3 KiB (14.5 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-west-2-337299574287/xgboost-200606-0559-019-e996df8f-2020-06-06-06-23-49-472/test.csv.out to .../data/boston/test.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXx09MqeGTA8"
   },
   "source": [
    "## Ouput visualization (scatter plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CP4VMuG-FTR6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Median Price vs Predicted Price')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dfZxcZXn/8c+VzUA2gGzAQGEhBJ9AESEQxL6wLSCCFYUIiqL1h8pPaluLFBoIlgoolCg+98EWH1EQEgFD0CrwM1CsbbCJmxBT4FV5MLChJEpWIAlks7l+f5x7NrOz55w5szNnZnbO9/167SszZ2bOuWc2e5177vu6r2PujoiIFMeUdjdARERaS4FfRKRgFPhFRApGgV9EpGAU+EVECkaBX0SkYBT4pSYzczN7Rbj9z2b2tx3Qpllm9ryZ9bS7La1mZo+b2Unh9sfN7GstOObxZvZkE/e31syOb9b+pD4K/F0kBIRtZvbSqu2rQvCe3egx3P0j7v6pRvdTLQSWHSGYP2dmD5vZB1Pasc7dd3f3kWa3pVFm9q3we3jezJ4xs7vN7NA8juXuf+fu/zdjm67Kow1h/25mm8N7HjSzz6edlN39MHe/N6/2SDoF/u7zGHB2+Y6ZHQ70tq85dVnv7rsDLwEuAb5qZq+pfpKZTW15y+r3mfBeDgA2AN+Ke9IkeS9ZHRHe85uA9wIfrn5Cl73fSUuBv/t8B/g/FffPAb5d+QQz29XMPmtm68zs6TB801vx+Hwze8rM1pvZh6peO9pzNLMZZvYDM9toZpvC7QMqnnuvmX3KzH4WevF3VX8bieORJcAm4DVmNjv0KM81s3XAsoptU8Ox9jKzb4Y2bzKzJRXteFv41jNkZv9hZq+LO274HD5bte12M7sw3L4k9GbL30jelOG9bAG+C7w27OMKM7vFzG4ws2eBD5jZFDNbYGaPmNlvzWyxme1V0Yb3m9mvw2N/U9W+K8zshor7bwzvccjMnjCzD5jZecD7gItDj/yO8Nz9zezW8Pt7zMzOr9hPb/hdbzKz/waOqfVeK97zQ8BPK97z4+GzewDYbGZTq4aresKQ1SPhs11pZgeGxw4N35ieCZ/5WVnbIckU+LvPcuAlZvbq8FX73cANVc/5NPAq4EjgFUA/8AkAM3sL8NfAm4FXAielHGsK8E3gIGAWsBX4h6rnvBf4ILAPsEvYd6oQCN8B9AFrKh76I+DVwCkxL/sOMB04LBzrC2FfRwHfAP4U2Bv4F2Cpme0as4/vAu82MwuvnQGcDNxsZocAHwWOcfc9Qhsez/BedicKugMVm08Hbgnv70bgfGBeeH/7E53w/jG8/jXAV4D3h8f2JvoWEXesWcCPgL8HZhL9fle5+3XhOJ8Jw2NvN7MpwB3AaqLf/5uAC8ys/NleDrw8/JxC1IHIJLT5D6re89nAqUCfu2+vesmF4fG3En3b+xCwxcx2A+4m+r3sE57zT2Z2WNa2SAJ310+X/BAFopOAy4BrgLcQ/eFMBRyYDRiwGXh5xet+H3gs3P4GsLDisVeF174i3P8WcFXC8Y8ENlXcvxe4rOL+nwM/Tnjt8cAOYAh4BlgFvCc8Nju04WUVzy9vmwrsF147I2a/XwE+VbXtYeCPYp5rwDrgD8P9DwPLwu1XEA3ZnASUavwevgW8EN7L/wJLy583cAVwX9XzHwTeVHF/P2A4vLdPADdXPLYbsA04qWJ/N4TblwLfT2nTVRX3jwXWVT3nUuCb4fajwFsqHjsPeDLlPTvwLNFJ6xHgKmBKxf/LD8X9X634fZwes893Az+t2vYvwOXt/lub7D8ab+tO3wHuAw6mapiHqCc4HVgZOrYQBbzyRNz+wMqK5/866SBmNp2oZ/0WYEbYvIeZ9fjOSdf/rXjJFmD3lHavd/fY3mzwRML2A4Fn3H1TzGMHAeeY2V9WbNuF6H2O4e5uZjcT9SzvI/q2ckN47FdmdgFRoD3MzO4ELnT39Qlt+qy7X5bxfRwEfN/MdlRsGwH2De0cfb67bzaz3ybs90CioJvFQcD+ZjZUsa2HaIiG6uOS8v+gwlHu/quEx5J+d5Dc7oOAY6vaOJXo/7c0QEM9Xcjdf000yftW4Laqh39DNCRzmLv3hZ89PZqUA3iK6A+xbFbKoS4CDgGOdfeXAH8YtlvySxqSVEr2CWAvM+tLeOzqivfa5+7T3f2mhH3dBLzTzA4i6hXfOnpw9++6+xuJApITDZk14308AfxxVRunufsgVb+PcLLdO2G/TxANzWQ95mNVx9zD3d8aHq/n/0EWaWWAk9r9BPBvVW3c3d3/rMG2FJ4Cf/c6FzjR3TdXbnT3HcBXgS+Y2T4AZtZfMba7mGjC8TUhyFyecow9iE4iQ2EyMu25uXH3p4jGtv8pTDiXzKx8Evoq8BEzO9Yiu5nZqWa2R8K+BoCNwNeAO919CMDMDjGzE8PcwAtE77tZqaT/DFwdTjaY2UwzOz08dgvwtjBpuwvwSZL/bm8ETjKzs8IE6t5mdmR47GngZRXP/TnwbJh07Q0TrK81s/Ik7mLg0vB5HgBUfmNqtq8BnzKzV4bf0evMbG/gB8CrwuR2KfwcY2avzrEthaDA36Xc/RF3X5Hw8CXAr4DlFmWW/D+injvu/iPgi8Cy8JxlKYf5IlGq6G+IJpV/3JzWT8j7icbFHyIai78AIHwGHyaadN5E9J4+UGNfNxGN5X+3YtuuwEKi9/q/RJONH29S279ENA9wl5k9R/RZHhvavxb4i9CWp8J7iF1I5e7riL7lXcTOeZIjwsNfJ8qQGjKzJWEo7u1E8zKPhff1NWDP8PwriYZ3HgPuIt/hlc8TnWjuIpon+DrQ6+7PEU2uvwdYT/S5f5rodyENMHddiEVEpEjU4xcRKRgFfhGRglHgFxEpGAV+EZGCyXUBl5k9DjxHlPa23d3nhrS/RUQrLx8HzkpYeDPqpS99qc+ePTvPpoqIdJ2VK1f+xt1nVm9vxcrdE9z9NxX3FwA/cfeFZrYg3L8kbQezZ89mxYqkzEQREYljZrErrtsx1HM6cH24fT1RcSoREWmRvAO/Ey1KWRlKwwLsG1Zalldc7hP3QjM7z8xWmNmKjRs35txMEZHiyHuo5zh3Xx9KA9xtZg9lfaFHpWSvA5g7d65WmYmINEmuPf5y5UJ33wB8H3g98LSZ7QcQ/t2QZxtERGSs3AJ/KIa1R/k2Uc2NXxLVJClf1OEc4Pa82iAiIuPlOdSzL1GN8fJxvuvuPzaz/wIWm9m5RBe9eFeObRARYcnAINfe+TDrh7ayf18v8085hHlz+tvdrLbJLfC7+6PsrAxYuf23RJd5ExHJ3ZKBQS69bQ1bh6Mq2oNDW7n0tuiKnkUN/lq5KyJd7do7Hx4N+mVbh0e49s6H29Si9lPgF5Gutn5oa13bi0CBX0S62v59vXVtLwIFfhHpavNPOYTeUs+Ybb2lHuafckibWtR+rajVIyLSNuUJXGX17KTALyJdb96c/kIH+moa6hERKRj1+EVEOkzeC84U+EVEOkgrFpwp8IuIxGhXmYe0BWcK/CIiOWlnmYdWLDjT5K6ISJV2lnloxYIzBX4RkSrtLPPQigVnCvwiIlXaWeZh3px+zjy6n56opD09Zpx5dHPXISjwi4hUaWeZhyUDg9y6cpARj644O+LOrSsHWTIw2LRjKPCLiFSZN6efa844nP6+Xgzo7+vlmjMOb3tWT7Moq0dEJEa7yjwoq0dEpGCU1SMiUjCtmF/QUI+ISAdpRRlpBX4RkQ6T9/yChnpERApGgV9EpGAU+EVECkaBX0SkYBT4RUQKRoFfRKRgFPhFRApGgV9EpGAU+EVECkaBX0SkYFSyQUSkwywZGFStHhGRolgyMMilt60ZvRjL4NBWLr1tDUDTgr+GekREOkgrrsClwC8i0kF0BS4RkYLRFbhERApGV+ASESkYXYFLRKSAJv0VuMysx8wGzOwH4f7BZna/mf2PmS0ys13yboOIiOzUijH+jwEPVtz/NPAFd38lsAk4twVtEBGRINfAb2YHAKcCXwv3DTgRuCU85XpgXp5tEBGRsfLu8X8RuBjYEe7vDQy5+/Zw/0kgdiDLzM4zsxVmtmLjxo05N1NEpDhyC/xm9jZgg7uvrNwc81SPe727X+fuc9197syZM3Npo4hIEeWZ1XMccJqZvRWYBryE6BtAn5lNDb3+A4D1ObZBRESq5Nbjd/dL3f0Ad58NvAdY5u7vA+4B3hmedg5we15tEBGR8dqxcvcS4EIz+xXRmP/X29AGEZHCaskCLne/F7g33H4UeH0rjisiIuOpVo+ISMEo8IuIFIwCv4hIwSjwi4gUjAK/iEjBqCyzSJdaMjCYa013mbwU+EW60JKBQS69bc3oRbsHh7Zy6W1rABT8RYFfpFtU9vCnmDHiY8tgbR0e4do7H1bgFwV+kW5Q3cOvDvpl64e2trJZ0qE0uSvSBa698+HRoJ9m/77eFrRGOp0Cv0gXyNKT7y31MP+UQ1rQGul0CvwiXaBveil2+xSLLoLR39fLNWccrvF9ATTGL9LRLluyhpvuf4IRd3rMOPvYA7lq3uHjnpcwpM9LppVYdfnJObdSJhsFfpEOddmSNdywfN3o/RH30fvVwf93W4dj95G0XYpNQz0iHeqm+5/IvD1p0laTuRJHgV+kQyWlZMZtn3/KIfSWesZs02SuJKkZ+C3yJ2b2iXB/lpnpQioiOesxy7x93px+rjnjcPr7ejWZKzVlGeP/J2AHcCLwSeA54FbgmBzbJVJ4Zx974Jgx/srtcebN6Vegl0yyBP5j3f0oMxsAcPdNZrZLzu0S6WpZCqiVJ3CzZPW0oj0Tea50piyBf9jMegAHMLOZRN8ARLpaXgGungJqcw/ai3se2sj6oa383p7TmHvQXg0fv5H2qPhbd8gyuftl4PvAPmZ2NfDvwN/l2iqRNisHuMGhrTg7A9ySgcGG9x1XXqFcQK1VbZhIe+p9rnSumoHf3W8ELgauAZ4C5rn79/JumEg75RngksorVG9PasNFi1dz8IIfctzCZU05CWRtT73Plc5Vc6jHzN4ArHX3fwz39zCzY939/txbJ9ImeQa4/ft6GYzZT3XOfdKxyumc5W8AK379zOhwUD1DUuWhrIRFv7FrAJLaPsWMJQODGu6ZJLIM9XwFeL7i/uawTaRr5bkgKmvOfZZjbR0e4cbl68YMB82/ZTVHXnlX6reCymGkOElrAOLaDtHJKI9hKMlHlsBv7jtXjLj7DlTqQbpcnguisubcJwXZatU99uERZ2jrcOq8QFoZ57Q1AOW2x60l0Fj/5JElgD9qZuezs5f/58Cj+TVJpP3KQS+vtMUsOffVbYi7qlYWcVfeShpGMuBnC06s2a6/WrQq9jGN9U8OWQL/R4gyey4j6lz8BDgvz0aJdIJOWBBV2YbqVEqIAnWWU0F1QE4aq9+zN768c7Ws8xTSmbJk9Wxw9/e4+z7uvq+7v9fdN7SicSKyU+UQEUSlG5wo+NdSHZDnn3IIpSnjX7l52/ZM4/SqDTS5JQZ+M7s4/Pv3Zvbl6p/WNVFEyubN6R8NuuVhn8rgP700/k86LiDPm9PP7tPGf+EfHvFM4/SqDTS5pQ31PBj+XdGKhohINnETsw7MmF7iheGxi+oNOPPo+CGrTVvia/VnHafvhKEwmZjEwO/ud4RSDa919/ktbJPIpNWKOjZJgTkukDtwz0MbY9uZND9QOSykujzdKXVy191HzOzoVjVGZDJrVR2bpInVJHEniqSFWwajw0Kqy9O9suTxD5jZUjN7v5mdUf7JvWUik0yr6tgk5fcnlO+PzbRJ+tbgjE0j7aS6PEsGBjlu4bKmlqsoqizpnHsBvyWqx1/mwG25tEhkkmpVHZtyYL5i6VqGKq6pG5fin5Rpk/Stob/iJNFJdXn07aO5svT457v7B6t+PpR7y0QmmVZe93benH522zW+39ZjVjPTJks6Ziddx7fTvn1Mdok9fjN7O/ANonr8O4Cz3P0/WtYykUlm/imHjFtgldTjbsakaVLPe4c7jy08NfW1WVYm1/N+8tZJ3z66QdpQz9XAH7j7Q2Z2LPAZ4I9a0yyRySdrmYdmDVs0unq2Vjpm3mUr6qGVws2VFvi3u/tDAO5+v5nt0aI2iUxaWXLbr7xjbeKwRT1BtRU98k7J1W/1t6lulxb49zGzC5Puu/vn82uWSHdaMjDY8MKpsk7qkeet1d+mul1a4P8qsEfK/VRmNg24D9g1HOcWd7/czA4GbibKFvoF8H5331Zvw0Umo7TJyLhhi1q9107pkbdClveaNglclM8pi7SVu1c2uO8XgRPd/XkzKwH/bmY/Ai4EvuDuN5vZPwPnogu7SEGk9eqrhy3Ue62fJoGzyZLOOSEeKV+5qxR+nGg9wC1h+/XAvLzaINJpkiYj+3pL44K5Uhjr10kpqJ0st8APYGY9ZrYK2ADcDTwCDLn79vCUJ4HYrouZnWdmK8xsxcaN42uNiExGSfnzV5x22Ljn1tt71cpWlYvOKtfA7+4j7n4kcADweuDVcU9LeO117j7X3efOnDkzz2aKtEw95Yzr6b1WXkM37ZKL3U7lorNJW8B1YdJjUF9Wj7sPmdm9wBuAPjObGnr9BwDrs+5HpBtknZCtJ4VRk5o7FWnCe6LSsnrKGTyHAMcAS8P9txNl66Qys5nAcAj6vcBJwKeBe4B3EmX2nAPcPrGmi9RvMuV415OuqUlNqUfNrB4zuws4yt2fC/evAL6XYd/7AdeHmv5TgMXu/gMz+2/gZjO7ChgAvt7YWxDJpp4smU45QWTtvWplq9QjS3XOWUBlnv02YHatF7n7A8CcmO2PEo33izRdWsDOOhwyGdMoO6mujnS+LIH/O8DPzez7RBOx7wC+nWurRCagVsBOGvao7ilPxvHyIq3ilcbVDPzufnVYePUHYdMH3X0g32aJ1K9WwE4aDjGik0Y5SDZjvLwdQ0V5TGp2ypCXNFfWdM7pwLPu/iXgyVB2QaSj1ArY8085hLiLVDljSyk0ugioW1Iru+V9yHg1A7+ZXQ5cAlwaNpWAG/JslMhE1ArY8+b0xy8aYexJo9FFQN2y4rZb3oeMl6XH/w7gNGAzgLuvp45ibSKtkiVg92fozTe6CKhbUiu75X3IeFkmd7e5u5uZA5jZbjm3SWRCmnlVqUbGy7sltbJb3oeMlyXwLzazfyFacfth4EPA1/JtlsjENHJVqfJE5uDQVnrMGHGnP2VCM2nisxmplZ0wqaoU0e6VJavns2b2ZuBZolW8n3D3u3NvmUhO4k4O1amgIx7NBiTl8GfJ9Z9o4O6UdQRKEe1e5p403RWeYPZpd7+k1rY8zZ0711esWNGqw0kBHbdwWeywRll/Xy8/W3BizedXP6+ZbWnGvqVYzGylu8+t3p5lcvfNMdv+uPEmieRjIuWJa01YVj+e58SnJlUlb4mB38z+zMzWAIea2QMVP48Ba1rXRJHsJpp7XmvCsvrxPC/4oYuJSN7SevzfJarEeXv4t/xztLu/rwVtE6lbUu75BYtWpfb+41JBy+ImNE84NP4aEUnb66GLiUje0qpz/g74nZl9CXimojrnHmZ2rLvf36pGipTFZbvAzgnItBmrtEnSyonMLFk99zwUf1W4pO310KSq5C3L5O4AUVnmch7/FGCFux/VgvYBmtyVSHW2C0BpioHB8Ej6/+NKzZgkPXjBD2NPMgY8tvDUhvYt0iyNTO6aV5wd3H0H2fL/RZoqbhhneIfXFfShOZOkGoeXySxL4H/UzM43s1L4+RjwaN4NE6nWrKyWZgTnpHH4Ew6dWfgLnkvny9Jz/wjwZeAyokKGPwHOy7NRInFj+X3TS2zaMpzp9eWx+bxWnsaNw59w6ExuXTnY9oVXIrVkWbm7AXhPC9oiAsSvXJ1/y2pGMg7plIN7Odheecfa0RPGrlOzViKvrXoF8HELl026C7hIMSUGfjO72N0/Y2Z/D+Pnsdz9/FxbJpPeROvNxI7lZwz6Bpx59NiA/MLwjtHbQ1uHc+uFa+GVTBZpPf4Hw79Kp5G6NVJvppFA6YxNqWzlZRRVzVImi7Q8/jvCv9e3rjnSLRoJuPWM5cepPHG0sheuapYyWaQN9dxBzBBPmbuflkuLpCs0EnBrLC2pqbKH3cpeuBZeyWSRNtTz2fDvGcDvsfNyi2cDj+fYJukCjQTc322deG/fYEwPu9W98DwueC7SbIkpDu7+b+7+b8Acd3+3u98Rft4LvLF1TZTJqJF6MxPtjRvwvjfMGhN4583p58yj++mx6DLrPWbjJn+baSKVQUVaLUse/0wze5m7PwpgZgcDjVeikq5Wz7BHdfZPdT58mhnTSwxtGU7c/5KBQW5dOTh6YZURd25Yvo4frH6KK047rKkngE65gIpILVkC/18B95pZebXubOBPc2uRdI0swx5xwfLWlYMcNWtPlj+6aTRgx5lemsL0XaYylDARvGRgkIsWr47dx9DWYeZ/b/VoO5uhlRlEIo3IsoDrx2b2SuDQsOkhd38x32ZJM3TCdVtrSQqW//HIM6mVNktTjOEdPjqPUN27Lp9Q0k4cwzucK5aubdpnojx+mSxqLmM0s+nAfOCj7r4amGVmb8u9ZdKQiV6QpBnHrWeMOykoxoXrHjOMqBzD7tOmjlvUVe5dQ/wJJc5QAxPJ1VS4TSaLLOvXvwlsA34/3H8SuCq3FklTpA075CXuZHPBolXM+eRdiSeAvumlzPvf4c5jC0/lZwtOTMzzL38DaEcvWxdQkckiS+B/ubt/BhgGcPetRAkU0sHaMeyQ1MvetGU49tvGkoFBnn9he+b9O3DkldFJpJylU628PWsve0YdJ55a5s3p55ozDqe/r3f0m8k1ZxzeccNrIlkmd7eZWS/h27eZvRzQGH+Ha0f5gLSTStwk57V3PszwjvpWa5UnZZPG7svb4/L3q5V6jMvfflhdx69FefwyGWTp8V8O/Bg40MxuJCrLfHGurZKGtWPYodZJpfrEMNFvH8M7PLHH3x/aENf7/pM3zBpz/9p3HqEgLYWU2uM3MwMeIlq9+waiIZ6PuftvWtA2aUA7ygfU6mVXnxiSvpVkMeJOb6lnzLGMsRc7V+9bJF6Wa+6udPejW9SeWLrm7uSxZGCQK5auHZct01vq4ZozDgd2noz27C2xedv2ui+dCFGP/YRDZ3Lj8nVjMoDKx6kM+K1Ma50MKbRSHI1cc3e5mR2TQ5ukC82b08+qy0/mi+8+ctwkJzAm62do6/CYoF9PxsCWbdv5weqnxqV9VmcutTKttV0ptCL1yjK5ewLwETN7HNhM9Pfp7v66PBsmk1vcMEvcFaoq1dPvTyvbXDl30MrVtFq5K5NFlsD/x7m3QrpaefhjouP59aqcS2hlWqtW7spkkVaPfxrRhdZfAawBvu7u2ZOuRYiC/vzvra47bXOiqjOXWpnWqitwyWSR1uO/nmjR1k+Jev2vAT6WdcdmdiDwbaJa/juA69z9S2a2F7CIqNjb48BZ7r5pIo2XiYubhITsWUBpk5iVj2GNX1glzfTSFGbstmtim1tZj19X4JLJIjGrx8zWuPvh4fZU4OfuflTmHZvtB+zn7r8wsz2AlcA84APAM+6+0MwWADPc/ZK0fSmrp7mqK2JCVPQMG3tR87gMmaTXV2bt1Fo41UwzppcY+MTJY9rWyAmtUcrqkU6SlNWTFvh/URnoq+9PoAG3A/8Qfo5396fCyeFed0/tEinwN9dxC5dlHm/v7+vlZwtOzPT68uKpVo3lQ5Rp8NjCU4H0E5KCrxTRRNI5jzCzZ8PPc8DryrfN7Nk6Dz4bmAPcD+zr7k8BhH/3qWdf0rh6Jhvjnps2iZl137vt0jOa7jljeom+3qhmTr1FoCrHz69YurblhelEJqPEMX5370l6rB5mtjtwK3CBuz9rCUvtY153HnAewKxZs5rRFAnqWTEbNzFZaxIzy76vfkd8L7xyqGSKWWo9/crx8yUDg4kllpVVIzJWlgVcE2ZmJaKgf6O73xY2Px2GeMrzABviXuvu17n7XHefO3OmrvTYTHF1fEpTjFLP2JNy3MTkkoFBNr84Prmr/Ny4fVcz4IJFq5i94Iej1TbL5s3p52cLTuSxhafyubOOGLevcgurK1+m9eqVVSMyVpY8/gkJdX6+Djzo7p+veGgpcA6wMPx7e15tkHhJdXzitlWXPohLzZwxvcTlbz9sXOXNpJ5/5avTLoFYvl9ZAqIv5liQ3qtXVo3IWDVr9Ux4x2ZvJEoFXUOUzgnwcaJx/sXALGAd8C53fyZtX5rc7QxHXnlX7HBKX2+JVZefPG57PTn85UnkLBdej5uwTZpwrs76ESmSpMnd3Hr87v7vJM/VvSmv43aSbkjtq3wPSeE7aWz9yjvWZl64tX5oa+yF16uLsEF8GYSkHPpm19sX6Qa5jvEXWTcU7Kp+D7WeW30/rZ5Otf37emNr3SQdt3poR1e/EslOgT8n7bjm7UQlXSA96wXLy89Nu5+mNMWYf8ohdWXfaMJWZOJyG+opurwKdjVr+KiycJqxs2dd/mZSb1vLQzW1hoWq9fWWuOK0aLI2aUK4sn0QXTJx84vbOXjBD8dMTFcPE5Xfh3r9ImPlNrnbTJNxcjdtdWv1SthqScE9qdTC7tOmMrRlOPOJIG4/1fp6Szz3wvbUPPrq57+4fUddpRp6zPjcWUeMqfETN05/5tH93PPQRtYPbaVveonnX9g+Zu6gt9TDtNKU2KGlLJ+3SLdq+eRu0U20YFfcBGe55xo39DK8w0cDXlwvN+4kkmUIJ2nCNqmmjxl11+cZcR/T3iyXizxu4bJxAX7r8EjisbV4S2Q89fhzNJFhmbRvClmHUCpTI+NOPhMtoGYGXzjrSGB8cP6rRavqupBKXHuzOHjBD+s6jnr8UmTq8bfBRC72nTY3kLXUQnkfSRPMPTVKISQpvyTufTVyoZV6J3XjjhM31KSSyCLxlNXTYZKyVco961rlECr3kRRQR9xTSyHMmF5K3Hc5W6c6E+iEQ2dmaltaeyslZRrFfQa9pR6uOO0wpXOKZKQef4dJmxuoHgPfs7fE5m3bx423l3u5Sb3j/oqx/qQLqVywaFVs+5IWWt26cpAzj+7nhuXrUv2/yUIAAAxzSURBVN9f9VBTUj2gWhk6SW1XoBepTWP8HaieuYFaV8JKu2BK2jHSyjPUk+1TqdYJp6yRjCgR2Ulj/JNAdRD/wruPHE3jPG7hstj0zrQgmlaMrVaP+orTDotN+UzK9qnFYLR9tXrlumi5SL7U4+8QaTnscUXK0raXc94b7VEnLfKaiN7SFF4Y3pEpu0k9fpHmqPvSi52kCIE/KdglZeBkzcyJOxkkZd9UXsYwS9uyKk2xcQuu0iZedQlFkeaYyKUXpYXSMnDq2V5t6/AINy5fN6ZYXFLJ1KSMokaGWHrMxlXorFWzSAXXRPKlMf4OUc/lEOtVfYpwxte/Sct5T2tb3Ereyn1OdEXtRNZAiEg26vF3iKT89DQTzZuHKOhn7VEnrR/o6y1x7buO4Np3HkF/+LbQE66pXN5nf8K3iD17S7F5+iKSP/X4O0RSBk7Sitjy5Q4vWrw6ddgnaVK2nonSLDV00nrncYXlNm/bPpohpEqaIq2lwN9B4oY3Vvz6mdhFUb8Lhco+d9YR4wJrOdj3h0sXLvr5E2PG2cv179PEpYpOJKMm7qSxZdv22EJr1VfVEpF8KPBn1I7LKC4ZGOSm+5+IfWwHUTAtB+OkC5IvGRhk0X+N3cfwDufKO9YC8T3sLCtn61F9Qjt4wQ9jn6c8fZHW0Bh/Bu24jGL5mGnDOJWB8sXtO0Zvb9oyPNq+a+98OHbitfI51fK+elhaPSIRyZ8CfwbtuIxilpr5e/aWarYvrRed9B7yXjmbNJGtSpoiraHAn0E7Sghk2ffmbdtZMjBYs5RzvcfJu0euPH2R9tIYfwZJeex5Dk1kyesfHnEuWryaPXtLsTV0ynMRaZdZjHsPE716WD2Upy/SPurxZ9COoYmstfdH3Nm8bXu0kKpCZSnna844nL7e8TX2k96DeuQi3U21ejJqV1ZP+ZhTatTmmTG9xPRdpqa2rx3vQUTaR0XaOshEAnBc4bJq5evy5hHUddIQmXxUjz9FK4PaRHPky4+lrdQtzwk0eyVss/P6RaS9Cj/G3+oc/UZSQ+fN6edzZx2Raey/memm7UhnFZH8FD7wtzqoNSM1dFop26+tWemmuiKWSHcpfOBvdVBrJEe+/O2kus5Nvceql1bainSXwgf+Vge1Wqmh5evrxpUrzrKaN26febdZRCaXwgf+Vga18iTy1uGRcXXrywXV0uYbsn4L6estNTXvXnn9It2l8Fk9WWrNN0N1ZsyI+5hFVuU2JM03zJvTT9/0UuwwzxQDd3LNSNJKW5HuUajAn5S22YqgViuoQ+35hqQlFy+ZVmLV5Sc3r7Ei0tUKM9TTjtLKlbJMIteab/hdTD2etO0iInEKE/jbnYueZRK51nyDsmtEpBkKE/jbnYueZRK51iSqsmtEpBkKM8afd2nlWmUfsk4ip803tGoiWkS6W2GKtMUVOest9TQlLTHPfYuITFTLi7SZ2TeAtwEb3P21YdtewCJgNvA4cJa7b8qrDZWSessAxy1cxvqhrezZW8IMhrYM19WbzpKxk0aVL0WklfIc6vkW8A/Atyu2LQB+4u4LzWxBuH9Jjm0Yo3oYpbqnXnkVq3oqUDYyf6DKlyLSarlN7rr7fcAzVZtPB64Pt68H5uV1/CxqlUDImvXTSLZNu7ONRKR4Wp3Vs6+7PwUQ/t0n6Ylmdp6ZrTCzFRs3bsylMVl65Fme00i2TZZvC2n1e0RE6tWx6Zzufp27z3X3uTNnzszlGFl65Fme00gtm1rfFtq98ExEuk+r0zmfNrP93P0pM9sP2NDi448x/5RDUi9nWE+O/ETLPsS1ofK4jU4ci4hUa3WPfylwTrh9DnB7i48/RnVPva+3xIzppZZWoKz1baHdC89EpPvkmc55E3A88FIzexK4HFgILDazc4F1wLvyOn5WnVB1Mq0NeS88E5HiyS3wu/vZCQ+9Ka9jdqNaQ0EiIvXq2pIN3bIoSmUaRKTZujLwd9uiqE4YjhKR7tGx6ZyN0KIoEZFkXdnj76RMmG4ZchKR7tGVPf5OuWCJFl+JSCfqysCfxwVLJlI2QUNOItKJunKop9mZMBOdLO6kIScRkbKuDPzQ3EyYiZZN0OIrEelEXTnU02wT7bnrGrki0okU+DOY6GRxI1U7RUTy0rVDPc3USNkELb4SkU6jwJ+ByiaISDdR4M9IPXcR6RYa4xcRKRgFfhGRglHgFxEpGAV+EZGCUeAXESkYc/d2t6EmM9sI/Lrd7ajTS4HftLsRHUafyVj6PMbTZzJWo5/HQe4+s3rjpAj8k5GZrXD3ue1uRyfRZzKWPo/x9JmMldfnoaEeEZGCUeAXESkYBf78XNfuBnQgfSZj6fMYT5/JWLl8HhrjFxEpGPX4RUQKRoFfRKRgFPibwMy+YWYbzOyXFdv2MrO7zex/wr8z2tnGVjKzA83sHjN70MzWmtnHwvYifybTzOznZrY6fCZXhu0Hm9n94TNZZGa7tLutrWRmPWY2YGY/CPeL/nk8bmZrzGyVma0I25r+d6PA3xzfAt5StW0B8BN3fyXwk3C/KLYDF7n7q4E3AH9hZq+h2J/Ji8CJ7n4EcCTwFjN7A/Bp4AvhM9kEnNvGNrbDx4AHK+4X/fMAOMHdj6zI32/6340CfxO4+33AM1WbTweuD7evB+a1tFFt5O5Pufsvwu3niP6w+yn2Z+Lu/ny4Wwo/DpwI3BK2F+ozMbMDgFOBr4X7RoE/jxRN/7tR4M/Pvu7+FESBENinze1pCzObDcwB7qfgn0kY1lgFbADuBh4Bhtx9e3jKk0QnyKL4InAxsCPc35tifx4QdQbuMrOVZnZe2Nb0vxtdgUtyY2a7A7cCF7j7s1GHrrjcfQQ40sz6gO8Dr457Wmtb1R5m9jZgg7uvNLPjy5tjnlqIz6PCce6+3sz2Ae42s4fyOIh6/Pl52sz2Awj/bmhze1rKzEpEQf9Gd78tbC70Z1Lm7kPAvUTzH31mVu6AHQCsb1e7Wuw44DQzexy4mWiI54sU9/MAwN3Xh383EHUOXk8OfzcK/PlZCpwTbp8D3N7GtrRUGKv9OvCgu3++4qEifyYzQ08fM+sFTiKa+7gHeGd4WmE+E3e/1N0PcPfZwHuAZe7+Pgr6eQCY2W5mtkf5NnAy8Ety+LvRyt0mMLObgOOJSqg+DVwOLAEWA7OAdcC73L16ArgrmdkbgZ8Ca9g5fvtxonH+on4mryOamOsh6nAtdvdPmtnLiHq8ewEDwJ+4+4vta2nrhaGev3b3txX58wjv/fvh7lTgu+5+tZntTZP/bhT4RUQKRkM9IiIFo8AvIlIwCvwiIgWjwC8iUjAK/CIiBaPAL5OembmZfafi/lQz21iu+FjHfu41s7nh9r+W8+4bbNsHQltWmdl/m9mHE54318y+3OjxRLJQyQbpBpuB15pZr7tvBd4MDDayQ3d/a1NaFlnk7h8Ny/DXmtlSd3+6/KCZTXX3FcCKJh5TJJF6/NItfkRU6RHgbOCm8gNhReQ3zOy/Qu3308P2XjO72cweMLNFQG/Fax43s5eG20tC0ay1FYWzMLPnzezqUGN/uZntm9bAsAz/EeAgM7vCzK4zs7uAb5vZ8RU16Xc3s2+GuuwPmNmZYfvJZvafZvYLM/teqIUkUjcFfukWNwPvMbNpwOuIVgmX/Q1RSYBjgBOAa8OS+D8Dtrj764CrgaMT9v0hdz8amAucH1ZSAuwGLA819u8DYodxysLKzJcBvwqbjgZOd/f3Vj31b4HfufvhoW3LwknoMuAkdz+K6NvBhWnHE0mioR7pCu7+QCgBfTbwr1UPn0xUEOyvw/1pRMvf/xD4csXrH0jY/flm9o5w+0DglcBvgW1AeR5hJdEQU5x3hzIWLwJ/6u7PhEqlS8PQVLWTiOrXlN/bplDN8jXAz8JrdwH+M+F4IqkU+KWbLAU+S1Q3ae+K7Qac6e4PVz45BNDUmiWhjsxJwO+7+xYzu5foxAEw7DtrnoyQ/Pe0yN0/GrN9c9JhY9plwN3ufnZae0Wy0FCPdJNvAJ909zVV2+8E/jJUDcXM5oTt9wHvC9teSzREVG1PYFMI+ocSlVLO213A6IkiXGN1OXCcmb0ibJtuZq9qQVukCynwS9dw9yfd/UsxD32K6FKHD5jZL8N9gK8Au4chnouBn8e89sfA1PCcTxEF4LxdBcwws1+a2Wqia7BuBD4A3BTashw4tAVtkS6k6pwiIgWjHr+ISMEo8IuIFIwCv4hIwSjwi4gUjAK/iEjBKPCLiBSMAr+ISMH8fwA7l3kYW3OyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "plt.scatter(y_test, _pred)\n",
    "plt.xlabel(\"Median Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Median Price vs Predicted Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLniLdj9GtLN"
   },
   "source": [
    "### Important Observation:\n",
    "\n",
    "In sagemaker, we have notebook instance in sagemaker, and on one instance I am going to train other models (... that you can see it in its parent folder), so if we trained this model in notebook means some space of instance must be used. Or, may be more (90 to 95 % of total..(just assume)) \n",
    "\n",
    "In such case, if I run other notebook then due to unavailable space it will give error, and its hard to solve sometime. So, its better to delete this data directory. \n",
    "\n",
    "- You can do it from terminate notebook stance also.\n",
    "\n",
    "***Keep in mind*, IT WILL LOSS YOUR ALL DATA**, even given **INPUT DATA**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEUH0aZ-FTPr"
   },
   "outputs": [],
   "source": [
    "# remove all the files from data_dir\n",
    "!rm $data_dir/*\n",
    "\n",
    "# remove directory\n",
    "!rmdir $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fAwYFU2aH6LC"
   },
   "source": [
    "### Summary \n",
    "Let's revise \n",
    "The flow of notebook  ...\n",
    "1. Download or otherwise retrieve the data.\n",
    "2. Process / Prepare the data.\n",
    "3. Upload the processed data to S3.\n",
    "4. Train a chosen model.\n",
    "5. Test the trained model (typically using a batch transform job).\n",
    "6. Deploy the trained model.\n",
    "7. Use the deployed model.\n",
    "\n",
    "Thats all, please visit [image_folder]() to see aws working screenshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqrUT1T-FTMU"
   },
   "outputs": [],
   "source": [
    "# \"Keep Learning, Enjoy Empowering\" @dave117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO8fRQCUlOMbUYhkz1VU7FE",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Boston_House(AWS-SageMaker.Batch_Transform/HP_Tuning).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
