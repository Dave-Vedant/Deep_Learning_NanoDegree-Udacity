{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vedantdave77/project.Orca/blob/master/ML%20deployment-%20AWS.SageMaker/Boston_House(AWS_SageMaker_Deploy_Model).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIWbGtVPjtnQ"
   },
   "source": [
    "# AWS SAGEMAKER \n",
    "Hello, I am [Vedant_Dave](vedantdave77@gmail.com), a data enthusiast with deep interest in machine learning and deep learning. \n",
    "\n",
    "## Intro To Topic\n",
    "Today, I am going to deploy Boston Housing data Project using AWS Sagemaker's High level API called - \"Python SDK\". \n",
    "> This API has facility to train and deploy model in cloud directly from innner Jupyter notebook creation. So, I will use simple Machine learning workflow as usaual. \n",
    "\n",
    "> Data loading --> Data Preparation --> Model Training --> HP Tuning --> Deployment in AWS. (Hopefully, try to make Web Application). \n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "First of all, I will use SageMaker's batch transform feature, which  is a high-performance and high-throughput method for transforming data and generating inferences. \n",
    "\n",
    "- I personally think, It's ideal for scenarios where you're dealing with large batches of data, don't need sub-second latency, or need to both preprocess and transform the training data. \n",
    "\n",
    "- My main focus is to deploy model, so on analytic point of view, I tried to use Sagemaker's ML library and find median housing price for specific housing requrements in certain areas. \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB3yDsFIJB_W"
   },
   "source": [
    "## Set Environment (lib & SageMaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gslpcnrwJiMC"
   },
   "outputs": [],
   "source": [
    "# Setting-up Notebook in relevant environment.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOtUDtqJmNcg"
   },
   "outputs": [],
   "source": [
    "# set sagemaker in env.\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# Object to represent current active session of sagemaker - contains some useful info. for future usage.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# object shows IAM role - will help us to assign training job to sagemaker.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gP7UA5RHoG1c"
   },
   "source": [
    "## Download Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGz26OMNoDnN"
   },
   "outputs": [],
   "source": [
    "# get data from sagemaker library\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQ1Ldf2HoXgX"
   },
   "source": [
    "## Data preparation and splitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5HXQWXdoDkW"
   },
   "outputs": [],
   "source": [
    "# prepare data for python notebook\n",
    "X_bos_pd = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y_bos_pd = pd.DataFrame(boston.target)\n",
    "\n",
    "# splitting into train and test\n",
    "X_train,X_test,y_train,y_test = sklearn.model_selection.train_test_split(X_bos_pd, y_bos_pd, test_size =0.33)\n",
    "\n",
    "# further splitting of train to train(2/3) and validation(1/3)\n",
    "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X_train, y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9mDXm4qQPo"
   },
   "source": [
    "## Uploading dataa files to S3.\n",
    "\n",
    "Keep in mind that, \n",
    "\n",
    "- When a training job is constructed using SageMaker, a container is executed which performs the training operation.\n",
    "- This container is given access to data that is stored in S3. This means that we need to upload the data we want to use for training to S3. \n",
    "- In addition, when we perform a batch transform job, SageMaker expects the input data to be stored on S3. We can use the SageMaker API to do this and hide some of the details, but first data saved locally and then uploaded to S3 container.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yc2SI2v4xy92"
   },
   "outputs": [],
   "source": [
    "# define & ensure data dictionary...\n",
    "data_dir = '.../data/boston'\n",
    "if not os.path.exists(data_dir):\n",
    "  os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYQAaia5oDiK"
   },
   "outputs": [],
   "source": [
    "# In data_dir, I amd creating csv file format for all data, and in validation and train set target data comes in first columns.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir,'test.csv'),header = False, index = False)\n",
    " \n",
    "pd.concat([y_val,X_val], axis =1).to_csv(os.path.join(data_dir, 'validation.csv'),header=False, index= False)\n",
    "pd.concat([y_train,X_train],axis =1).to_csv(os.path.join(data_dir,'train.csv'),header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4w9BxAIs13oi"
   },
   "source": [
    "### Upload to S3 - data storage.\n",
    "Its good prectice to give prefix to your S3 bucket, so you can easily get idea about specific container for relevant project. \n",
    "- Here, I am giving name as \"dataset_name-algorithm_name-API_level\".\n",
    "\n",
    "I will use xgboost algorithm, which is one of the modern approach for supervised learning. It boost our algorithm gradient and give high accuracy result with good F1 score Matrix. \n",
    "\n",
    "> For more info, visit [XGBoost](https://xgboost.readthedocs.io/en/latest/) official documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rq5Uhd5doDel"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n",
      "'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n",
      "'upload_data' method will be deprecated in favor of 'S3Uploader' class (https://sagemaker.readthedocs.io/en/stable/s3.html#sagemaker.s3.S3Uploader) in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "prefix = 'boston-xgboost-HL'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir,'test.csv'),key_prefix = prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir,'validation.csv'), key_prefix = prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir,'train.csv'),key_prefix = prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pXKWD1V_36wO"
   },
   "source": [
    "## Training XGBoost Model\n",
    "There are two options for training model either use high-level API in which Sage-Maker will train algorithm ownself or from low level API inwhich we need to define our own work. \n",
    "\n",
    "I will go with both the cases to represent difference. Before this we must need some important information for sagemaker to give permissions and you can find them from [common_para_list](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXtdSvnHoDa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.amazon.amazon_estimator:'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n",
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# define container with uri to define container with session and ml-model info.\n",
    "container = get_image_uri(session.boto_region_name,'xgboost')\n",
    "\n",
    "# Now construct container object with requried parametrs.\n",
    "xgb = sagemaker.estimator.Estimator(container,                                   # our training container\n",
    "                                    role,                                       # defined IAM role for training\n",
    "                                    train_instance_count=1,                     # instaces, depend how many you created - for lengthy job need more\n",
    "                                    train_instance_type = 'ml.m4.xlarge',       # type of instace type for deployjent - can use m2 to m5 (AWS rate will according to that, check here --> https://aws.amazon.com/sagemaker/pricing/)\n",
    "                                    output_path = 's3://{}/{}/output'.format(session.default_bucket(),prefix),   # output destination\n",
    "                                    sagemaker_session=session)                  # current session (because instance are on regionwise servers, s3 bucket is globalize platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjnFyDbzCRO9"
   },
   "source": [
    "> ***SageMaker has xgb HP tuning parameters as follow, you  can check it*** [here](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8uFTgAYkoDYW"
   },
   "outputs": [],
   "source": [
    "# set HyperParameter of model.\n",
    "xgb.set_hyperparameters(max_depth= 5,\n",
    "                        etz = 0.2,\n",
    "                        min_child_weight= 6,\n",
    "                        subsample = 0.8,\n",
    "                        objective = 'reg:linear',\n",
    "                        early_stopping_round = 10,\n",
    "                        num_round = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHH4FRGZoDVs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 07:07:45 Starting - Starting the training job...\n",
      "2020-06-06 07:07:47 Starting - Launching requested ML instances......\n",
      "2020-06-06 07:08:56 Starting - Preparing the instances for training......\n",
      "2020-06-06 07:09:59 Downloading - Downloading input data...\n",
      "2020-06-06 07:10:42 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-06-06:07:10:42:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-06-06:07:10:42:INFO] File size need to be processed in the node: 0.02mb. Available memory size in the node: 8480.23mb\u001b[0m\n",
      "\u001b[34m[2020-06-06:07:10:42:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:10:42] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[07:10:42] 227x13 matrix with 2951 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-06-06:07:10:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:10:42] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[07:10:43] 112x13 matrix with 1456 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:16.2765#011validation-rmse:18.6081\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:11.8459#011validation-rmse:13.7746\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:8.79065#011validation-rmse:10.2204\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:6.74536#011validation-rmse:7.92744\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:5.30365#011validation-rmse:6.25183\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:4.25085#011validation-rmse:5.16067\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:3.52529#011validation-rmse:4.42145\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:2.99896#011validation-rmse:3.90318\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:2.66778#011validation-rmse:3.64173\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:2.41748#011validation-rmse:3.51187\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:2.26194#011validation-rmse:3.39157\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:2.1798#011validation-rmse:3.26479\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:2.07585#011validation-rmse:3.28694\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:1.98084#011validation-rmse:3.21826\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:1.91962#011validation-rmse:3.19715\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:1.82437#011validation-rmse:3.24084\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:1.74926#011validation-rmse:3.18724\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:1.645#011validation-rmse:3.22734\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:1.56519#011validation-rmse:3.28272\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:1.49614#011validation-rmse:3.25485\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:1.40423#011validation-rmse:3.31688\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:1.36762#011validation-rmse:3.33445\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:1.33339#011validation-rmse:3.34521\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:1.26297#011validation-rmse:3.3386\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:1.23879#011validation-rmse:3.34969\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:1.19371#011validation-rmse:3.36466\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:1.17813#011validation-rmse:3.34606\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:1.16115#011validation-rmse:3.36221\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:1.08537#011validation-rmse:3.33792\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:1.02734#011validation-rmse:3.36589\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:1.01171#011validation-rmse:3.37204\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.952354#011validation-rmse:3.36669\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.903774#011validation-rmse:3.35576\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.876226#011validation-rmse:3.35691\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.830406#011validation-rmse:3.37899\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.808806#011validation-rmse:3.38462\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.787723#011validation-rmse:3.39107\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.773395#011validation-rmse:3.39659\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.74775#011validation-rmse:3.40161\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.735809#011validation-rmse:3.40627\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.714094#011validation-rmse:3.39824\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.683763#011validation-rmse:3.39753\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.669408#011validation-rmse:3.40576\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.643954#011validation-rmse:3.39108\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.630443#011validation-rmse:3.38548\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.616763#011validation-rmse:3.4007\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.604592#011validation-rmse:3.40118\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.592376#011validation-rmse:3.38991\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.56709#011validation-rmse:3.37715\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.554218#011validation-rmse:3.37754\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:0.544921#011validation-rmse:3.37093\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:0.52264#011validation-rmse:3.36126\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:0.502149#011validation-rmse:3.36416\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:0.485112#011validation-rmse:3.35972\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:0.478046#011validation-rmse:3.36423\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:0.463661#011validation-rmse:3.37602\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:0.460328#011validation-rmse:3.37456\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:0.44906#011validation-rmse:3.3652\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:0.432778#011validation-rmse:3.36708\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:0.416396#011validation-rmse:3.36638\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:0.407207#011validation-rmse:3.363\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:0.393048#011validation-rmse:3.36297\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:0.388279#011validation-rmse:3.36084\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:0.371989#011validation-rmse:3.36171\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:0.364655#011validation-rmse:3.36615\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.356643#011validation-rmse:3.36433\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:0.346924#011validation-rmse:3.363\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:0.328093#011validation-rmse:3.36981\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:0.314267#011validation-rmse:3.37067\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:0.30573#011validation-rmse:3.36617\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:0.293335#011validation-rmse:3.3691\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:0.286186#011validation-rmse:3.37192\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:0.280188#011validation-rmse:3.38307\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:0.276139#011validation-rmse:3.38543\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:0.269444#011validation-rmse:3.37885\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:0.260115#011validation-rmse:3.37901\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[76]#011train-rmse:0.256109#011validation-rmse:3.37366\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-rmse:0.25072#011validation-rmse:3.37491\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[78]#011train-rmse:0.24642#011validation-rmse:3.37021\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[79]#011train-rmse:0.235095#011validation-rmse:3.3675\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[80]#011train-rmse:0.230208#011validation-rmse:3.36549\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[81]#011train-rmse:0.224503#011validation-rmse:3.367\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[82]#011train-rmse:0.216941#011validation-rmse:3.37269\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[83]#011train-rmse:0.20978#011validation-rmse:3.37011\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[84]#011train-rmse:0.205233#011validation-rmse:3.36809\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[85]#011train-rmse:0.202085#011validation-rmse:3.36988\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[86]#011train-rmse:0.197993#011validation-rmse:3.375\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[87]#011train-rmse:0.193762#011validation-rmse:3.37389\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[88]#011train-rmse:0.190924#011validation-rmse:3.37154\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[89]#011train-rmse:0.188301#011validation-rmse:3.36562\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[90]#011train-rmse:0.181097#011validation-rmse:3.36056\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[91]#011train-rmse:0.174383#011validation-rmse:3.36326\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[92]#011train-rmse:0.16761#011validation-rmse:3.36342\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[93]#011train-rmse:0.164782#011validation-rmse:3.36473\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[94]#011train-rmse:0.159853#011validation-rmse:3.3623\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[95]#011train-rmse:0.149866#011validation-rmse:3.36617\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[96]#011train-rmse:0.145696#011validation-rmse:3.36605\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[97]#011train-rmse:0.142461#011validation-rmse:3.36756\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[98]#011train-rmse:0.139011#011validation-rmse:3.36914\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[99]#011train-rmse:0.135716#011validation-rmse:3.37093\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[100]#011train-rmse:0.132767#011validation-rmse:3.36823\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[101]#011train-rmse:0.130303#011validation-rmse:3.37022\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[102]#011train-rmse:0.123244#011validation-rmse:3.36848\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[103]#011train-rmse:0.121371#011validation-rmse:3.3686\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[104]#011train-rmse:0.119289#011validation-rmse:3.36641\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[105]#011train-rmse:0.115602#011validation-rmse:3.36753\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[106]#011train-rmse:0.111263#011validation-rmse:3.36901\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[107]#011train-rmse:0.108829#011validation-rmse:3.36717\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[108]#011train-rmse:0.10664#011validation-rmse:3.36779\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[109]#011train-rmse:0.103681#011validation-rmse:3.36681\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[110]#011train-rmse:0.101121#011validation-rmse:3.36656\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[111]#011train-rmse:0.099122#011validation-rmse:3.36418\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[112]#011train-rmse:0.097104#011validation-rmse:3.36297\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[113]#011train-rmse:0.094793#011validation-rmse:3.3632\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[114]#011train-rmse:0.091606#011validation-rmse:3.36333\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[115]#011train-rmse:0.088949#011validation-rmse:3.3622\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[116]#011train-rmse:0.087512#011validation-rmse:3.36223\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[117]#011train-rmse:0.084684#011validation-rmse:3.362\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[118]#011train-rmse:0.082284#011validation-rmse:3.36171\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[119]#011train-rmse:0.081394#011validation-rmse:3.36286\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[120]#011train-rmse:0.079932#011validation-rmse:3.36131\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[121]#011train-rmse:0.07673#011validation-rmse:3.36249\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[122]#011train-rmse:0.074622#011validation-rmse:3.36345\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[123]#011train-rmse:0.073363#011validation-rmse:3.36323\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[124]#011train-rmse:0.072064#011validation-rmse:3.36462\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[125]#011train-rmse:0.071169#011validation-rmse:3.36426\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[126]#011train-rmse:0.069122#011validation-rmse:3.36444\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[127]#011train-rmse:0.068171#011validation-rmse:3.36297\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[128]#011train-rmse:0.066604#011validation-rmse:3.36227\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[129]#011train-rmse:0.064864#011validation-rmse:3.36211\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[130]#011train-rmse:0.062722#011validation-rmse:3.36353\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[131]#011train-rmse:0.061346#011validation-rmse:3.36435\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[132]#011train-rmse:0.059435#011validation-rmse:3.36438\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[133]#011train-rmse:0.058637#011validation-rmse:3.366\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[134]#011train-rmse:0.056654#011validation-rmse:3.36597\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[135]#011train-rmse:0.055997#011validation-rmse:3.366\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[136]#011train-rmse:0.055124#011validation-rmse:3.36529\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[137]#011train-rmse:0.054394#011validation-rmse:3.36533\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[138]#011train-rmse:0.052718#011validation-rmse:3.36544\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[139]#011train-rmse:0.05093#011validation-rmse:3.36491\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[140]#011train-rmse:0.049168#011validation-rmse:3.36464\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[141]#011train-rmse:0.048693#011validation-rmse:3.36472\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[142]#011train-rmse:0.047686#011validation-rmse:3.36524\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[143]#011train-rmse:0.046749#011validation-rmse:3.36415\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[144]#011train-rmse:0.044606#011validation-rmse:3.36337\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[145]#011train-rmse:0.043764#011validation-rmse:3.36301\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[146]#011train-rmse:0.042015#011validation-rmse:3.36314\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[147]#011train-rmse:0.040751#011validation-rmse:3.36332\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[148]#011train-rmse:0.040113#011validation-rmse:3.36347\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[149]#011train-rmse:0.03861#011validation-rmse:3.36417\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[150]#011train-rmse:0.038332#011validation-rmse:3.3643\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[151]#011train-rmse:0.037445#011validation-rmse:3.36408\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[152]#011train-rmse:0.036537#011validation-rmse:3.36437\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[153]#011train-rmse:0.035345#011validation-rmse:3.36504\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[154]#011train-rmse:0.034779#011validation-rmse:3.36575\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[155]#011train-rmse:0.034048#011validation-rmse:3.36585\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[156]#011train-rmse:0.033177#011validation-rmse:3.36551\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[157]#011train-rmse:0.031222#011validation-rmse:3.36477\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[158]#011train-rmse:0.030449#011validation-rmse:3.36444\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[159]#011train-rmse:0.029949#011validation-rmse:3.36452\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[160]#011train-rmse:0.029605#011validation-rmse:3.36488\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[161]#011train-rmse:0.029309#011validation-rmse:3.36507\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[162]#011train-rmse:0.029092#011validation-rmse:3.36519\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[163]#011train-rmse:0.028284#011validation-rmse:3.36525\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[164]#011train-rmse:0.027677#011validation-rmse:3.36571\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[165]#011train-rmse:0.027195#011validation-rmse:3.36527\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[166]#011train-rmse:0.025968#011validation-rmse:3.36464\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[167]#011train-rmse:0.025576#011validation-rmse:3.36462\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[168]#011train-rmse:0.025185#011validation-rmse:3.36473\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[169]#011train-rmse:0.024718#011validation-rmse:3.36526\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[170]#011train-rmse:0.023532#011validation-rmse:3.36556\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[171]#011train-rmse:0.023197#011validation-rmse:3.36541\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[172]#011train-rmse:0.023138#011validation-rmse:3.36532\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[173]#011train-rmse:0.022829#011validation-rmse:3.36486\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[174]#011train-rmse:0.022413#011validation-rmse:3.36431\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[175]#011train-rmse:0.021765#011validation-rmse:3.36448\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[176]#011train-rmse:0.021366#011validation-rmse:3.36441\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[177]#011train-rmse:0.020912#011validation-rmse:3.36454\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[178]#011train-rmse:0.020454#011validation-rmse:3.36441\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[179]#011train-rmse:0.020001#011validation-rmse:3.36425\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[180]#011train-rmse:0.019777#011validation-rmse:3.3639\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[181]#011train-rmse:0.019146#011validation-rmse:3.36375\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[182]#011train-rmse:0.018754#011validation-rmse:3.36371\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[183]#011train-rmse:0.018182#011validation-rmse:3.36365\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[184]#011train-rmse:0.018044#011validation-rmse:3.36374\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[185]#011train-rmse:0.01763#011validation-rmse:3.36337\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[186]#011train-rmse:0.017426#011validation-rmse:3.36346\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[187]#011train-rmse:0.017031#011validation-rmse:3.36369\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[188]#011train-rmse:0.016862#011validation-rmse:3.3637\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[189]#011train-rmse:0.016442#011validation-rmse:3.36353\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[190]#011train-rmse:0.015958#011validation-rmse:3.36347\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[191]#011train-rmse:0.015627#011validation-rmse:3.36299\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[192]#011train-rmse:0.015374#011validation-rmse:3.36267\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[193]#011train-rmse:0.015106#011validation-rmse:3.36284\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[194]#011train-rmse:0.01484#011validation-rmse:3.36299\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[195]#011train-rmse:0.014398#011validation-rmse:3.36316\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[196]#011train-rmse:0.014149#011validation-rmse:3.36303\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[197]#011train-rmse:0.013999#011validation-rmse:3.36308\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[198]#011train-rmse:0.01363#011validation-rmse:3.36299\u001b[0m\n",
      "\u001b[34m[07:10:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[199]#011train-rmse:0.013389#011validation-rmse:3.36305\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-06-06 07:10:54 Uploading - Uploading generated training model\n",
      "2020-06-06 07:10:54 Completed - Training job completed\n",
      "Training seconds: 55\n",
      "Billable seconds: 55\n"
     ]
    }
   ],
   "source": [
    "# give some more info to sagemaker about our input's data structure and arrangement\n",
    "s3_input_train = sagemaker.s3_input(s3_data= train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data= val_location, content_type='csv')\n",
    "\n",
    "xgb.fit({'train':s3_input_train,'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSQ_lAVreeJo"
   },
   "source": [
    "---\n",
    "\n",
    "**Attension:**\n",
    "***Hello, I am from past,*** if you visited my notebook on batch-transform method then you see the testing model phase, but in case of deployment of model the scenario is changed\n",
    "\n",
    "After deploying, I will test model in deployment environment and it helps us to get endpoint. - where we can get opportunity to give our own dataset outside of current dataset, menas you can apply your custom dataset by your own.\n",
    "\n",
    "Simply, \n",
    "\n",
    "> **AWS[S3(DATA) + sagemaker(MODEL) -+- [{ENDPOINT(access_link)} ] -+- host_platform(WEB_APPLICATION)] - user**\n",
    "\n",
    "Well, its use for application purpose. In app deployment we will see it further. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fr_EtAQUDXrM"
   },
   "source": [
    "## Deploy Model\n",
    "Now that we have fit our model to the training data, and used the validation data to avoid overfitting, we can deploy our model and test it. Deploying is very simple when we use the high level API, we need only call the `deploy` method of our trained estimator\n",
    "\n",
    "**NOTE:** When deploying a model you are asking SageMaker to launch an compute instance that will wait for data to be sent to it. As a result, this compute instance will continue to run until *you* shut it down. This is important to know since the cost of a deployed endpoint depends on how long it has been running for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeUMCepHoDT0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DS-cj2aPfrca"
   },
   "source": [
    "### Use Model in deployed environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxfJWfd1oDQs"
   },
   "outputs": [],
   "source": [
    "# We need to tell the endpoint what format the data we are sending is in\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "\n",
    "y_pred = xgb_predictor.predict(X_test.values).decode('utf-8')\n",
    "# predictions is currently a comma delimited string and so we would like to break it up as a numpy array.\n",
    "y_pred = np.fromstring(y_pred, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QV0QZe-oFdZG"
   },
   "source": [
    "Our Output will give us result after execution, here we get output from endpoint. So, no need to save output in S3 or no need to save model for future purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXx09MqeGTA8"
   },
   "source": [
    "## Ouput visualization (scatter plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CP4VMuG-FTR6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Median Price vs Predicted Price')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Median Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Median Price vs Predicted Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0NQHJXCgc5v"
   },
   "source": [
    "### Delete the endpoint\n",
    "The end point is used to transfer output of model out of sagemaker, I mean from web app. But, if you are not going to deploy by web app then its ok, and better to delete it. Becuase, the sagemeaker is still running and give you a cost of sagemaker and S3. Here by running the following cell you will delete the endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXBxLm4ggZQP"
   },
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLniLdj9GtLN"
   },
   "source": [
    "### Important Observation:\n",
    "The default notebook instance on SageMaker doesn't have a lot of excess disk space available. As you continue to complete and execute notebooks you will eventually fill up this disk space, leading to errors which can be difficult to diagnose. Once you are completely finished using a notebook it is a good idea to remove the files that you created along the way. \n",
    "\n",
    "- You can do it from terminate notebook stance also.\n",
    "\n",
    "***Keep in mind*, It will clear our all data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEUH0aZ-FTPr"
   },
   "outputs": [],
   "source": [
    "# remove all the files from data_dir\n",
    "!rm $data_dir/*\n",
    "\n",
    "# remove directory\n",
    "!rmdir $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fAwYFU2aH6LC"
   },
   "source": [
    "### Summary \n",
    "Let's revise \n",
    "The flow of notebook  ...\n",
    "1. Download or otherwise retrieve the data.\n",
    "2. Process / Prepare the data.\n",
    "3. Upload the processed data to S3.\n",
    "4. Train a chosen model.\n",
    "5. Test the trained model (typically using a batch transform job).\n",
    "6. Deploy the trained model.\n",
    "7. Use the deployed model.\n",
    "\n",
    "Thats all, please visit [image_folder]() to see aws working screenshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqrUT1T-FTMU"
   },
   "outputs": [],
   "source": [
    "# \"Keep Learning, Enjoy Empowering\" @dave117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Boston_House(AWS_SageMaker.Deploy_Model).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
