{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Mini-Project (Fashion-MNIST).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedantdave77/Project-Deep_Dream/blob/master/Mini_Project_(Fashion_MNIST).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcrcJLOU8GOX",
        "colab_type": "text"
      },
      "source": [
        "# Classifying Fashion-MNIST\n",
        "\n",
        "As previous project I will apply neural network, as per google the best performace can get around 97 %, but I will try to get answer as much possible.\n",
        "- Fashion MNIST is here as follow, you can download it, but I will use the PyTorch inner library dataset.|\n",
        "[Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ5N2Axa8GOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi_GotER8GOq",
        "colab_type": "text"
      },
      "source": [
        "Here we can see one of the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkbpfXQy8GOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "7f73e541-9878-4bad-adcf-1972dc2f923b"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "#print(images[0]) #Use it, just to see what image look like if you are NN\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap = None)\n",
        "print(labels[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n",
            "tensor(7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbmD4PVk8GO-",
        "colab_type": "text"
      },
      "source": [
        "## Building the network\n",
        "\n",
        "Here, I will use following parameter to train the network:\n",
        "> - loss : [Cross Entropy Loss](https://en.wikipedia.org/wiki/Cross_entropy)\n",
        "- Optimizer: [Adam optimizer](https://www.youtube.com/watch?v=JXQT_vxqwIs) explained by my personal favourite Andrew NG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0iQ4KSVBNpr",
        "colab_type": "text"
      },
      "source": [
        "building a self method network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgp3JHUtBTTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.view(x.shape[0],-1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x),dim =1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFjdsTML8GPa",
        "colab_type": "text"
      },
      "source": [
        "# Train the network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM68-rL58GPq",
        "colab_type": "code",
        "outputId": "6c5d009c-3f4c-4d18-c21b-96d4b83c55c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#@title Tuning Parameters { display-mode: \"both\" }\n",
        "learning_rate = 0.01 #@param {type:\"slider\", min:0.01, max:0.9, step:0.01}\n",
        "model = Classifier()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n",
        "epoches =  10    #@param {type:\"number\"}\n",
        "\n",
        "for e in range(epoches):\n",
        "  running_loss = 0\n",
        "  for images ,labels in trainloader:\n",
        "    output = model(images)\n",
        "    loss = criterion(output,labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    print('the total loss = {}'.format(running_loss/ len(trainloader)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the total loss = 1.6731426195422214\n",
            "the total loss = 1.8832275401046281\n",
            "the total loss = 1.9758804952666196\n",
            "the total loss = 1.8375002725292116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kpi8AGItH3R",
        "colab_type": "text"
      },
      "source": [
        "Some observations: just try it for experience: learning rate 0.1 (too high for our model) >> give us result around 2.014 and do not go lower than that is called local minima phenomena. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkUB9DKDK5_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# here helper module is changed so the supported view_classify does not work here is th defyning function for that.\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P1C1l2T8GPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import helper\n",
        "\n",
        "# Test out your network!\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[3]\n",
        "# Convert 2D image to 1D vector\n",
        "img = img.resize_(1, 784)\n",
        "\n",
        "# Give example to torch, pass from model\n",
        "ps = torch.exp(model(img))\n",
        "\n",
        "# Plot the image and probabilities\n",
        "view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk9guqOWLWXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[63]\n",
        "# Convert 2D image to 1D vector\n",
        "img = img.resize_(1, 784)\n",
        "\n",
        "ps = torch.exp(model(img))\n",
        "\n",
        "# Plot the image and probabilities\n",
        "view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1danaDQgKn-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keep Learning, Enjoy Empowering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6U2B3AVuC7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}