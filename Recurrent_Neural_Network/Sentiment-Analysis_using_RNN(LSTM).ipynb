{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment using RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsEaqQj+nN5yFJZpFJv84/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedantdave77/project.Orca/blob/master/Recurrent_Neural_Network/Sentiment-Analysis_using_RNN(LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoXQEmJ0YzNZ",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis with RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFnJe9wtYzKF",
        "colab_type": "text"
      },
      "source": [
        "##Intution:\n",
        "Previously I worked on Sentiment analytics using simple machine learning and deep learning algorithm, but the Accuracy was too low. \n",
        "\n",
        "So, here I am going to develop the same kind of sentiment analysis using RNN. I will use PyTorch library. I am aspecting a higher accuracy for the network. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tilIIFAtZqtv",
        "colab_type": "text"
      },
      "source": [
        "## Load Data and Dependencies \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RShLOY24Xye0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8d347273-843b-4bca-d49b-e2f12113a81e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "with open('/content/reviews.txt','r') as f:\n",
        "  reviews = f.read()\n",
        "with open('/content/labels.txt', 'r') as f:\n",
        "  label = f.read()\n",
        "\n",
        "print(reviews[:1000])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNJ2Ewz0aS2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a8de9c89-1867-4dc5-8e8a-b6c3507496d3"
      },
      "source": [
        "print(label[:100])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8AgAHfjavDX",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing \n",
        "\n",
        "You can see an example of the reviews data above. Here are the processing steps, we'll want to take:\n",
        "\n",
        "- We'll want to get rid of periods and extraneous punctuation.\n",
        "- Also, you might notice that the reviews are delimited with newline characters \\n. To deal with those,\n",
        "-  I'm going to split the text into each review using \\n as the delimiter.\n",
        "- Then I can combined all the reviews back together into one big string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwaVv8s0afce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "90163b86-349a-4909-f6a1-26408bb51f89"
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "# get rid of punctuation \n",
        "reviews = reviews.lower()\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "print(all_text[:30])\n",
        "\n",
        "# split by line and space to make individual words \n",
        "reviews_split = all_text.split('\\n')\n",
        "print(reviews_split[1])\n",
        "all_text = ' '.join(reviews_split)\n",
        "print(all_text[:30])\n",
        "\n",
        "# create list of words \n",
        "words = all_text.split(' ')\n",
        "len(words)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon com\n",
            "story of a man who has unnatural feelings for a pig  starts out with a opening scene that is a terrific example of absurd comedy  a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers  unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting  even those from the era should be turned off  the cryptic dialogue would make shakespeare seem easy to a third grader  on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond  future stars sally kirkland and frederic forrest can be seen briefly   \n",
            "bromwell high is a cartoon com\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5pBkC1Lb36G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "bd412f47-f677-4074-b5a3-d6091cb7baeb"
      },
      "source": [
        "words[0:30]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bromwell',\n",
              " 'high',\n",
              " 'is',\n",
              " 'a',\n",
              " 'cartoon',\n",
              " 'comedy',\n",
              " 'it',\n",
              " 'ran',\n",
              " 'at',\n",
              " 'the',\n",
              " 'same',\n",
              " 'time',\n",
              " 'as',\n",
              " 'some',\n",
              " 'other',\n",
              " 'programs',\n",
              " 'about',\n",
              " 'school',\n",
              " 'life',\n",
              " 'such',\n",
              " 'as',\n",
              " 'teachers',\n",
              " 'my',\n",
              " 'years',\n",
              " 'in',\n",
              " 'the',\n",
              " 'teaching',\n",
              " 'profession',\n",
              " 'lead',\n",
              " 'me']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk6jypZNdH07",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the words \n",
        "\n",
        "Teh best way is to create specific dictionary that map the words in the vocabulary to integer. So, We will have specific code (number) to represent each word. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtPLu3NWdFP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections  import Counter \n",
        "\n",
        "# Build a dictionary \n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts,key = counts.get, reverse = True)\n",
        "vocab_to_integer = {word: i for i, word in enumerate(vocab,1)}\n",
        "\n",
        "# same for review (1 and 0)\n",
        "reviews_to_integer = []\n",
        "for review in reviews_split:\n",
        "  reviews_to_integer.append([vocab_to_integer[word] for word in review.split()])\n",
        "                            "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0hov_MecF8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "326b171f-d176-4e3f-83a1-1fadcc40f59c"
      },
      "source": [
        "print('Unique words: ' , len((vocab_to_integer)))\n",
        "print()\n",
        "\n",
        "print('Tockenize the review: ',reviews_to_integer[:1])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words:  74072\n",
            "\n",
            "Tockenize the review:  [[21025, 308, 6, 3, 1050, 207, 8, 2138, 32, 1, 171, 57, 15, 49, 81, 5785, 44, 382, 110, 140, 15, 5194, 60, 154, 9, 1, 4975, 5852, 475, 71, 5, 260, 12, 21025, 308, 13, 1978, 6, 74, 2395, 5, 613, 73, 6, 5194, 1, 24103, 5, 1983, 10166, 1, 5786, 1499, 36, 51, 66, 204, 145, 67, 1199, 5194, 19869, 1, 37442, 4, 1, 221, 883, 31, 2988, 71, 4, 1, 5787, 10, 686, 2, 67, 1499, 54, 10, 216, 1, 383, 9, 62, 3, 1406, 3686, 783, 5, 3483, 180, 1, 382, 10, 1212, 13583, 32, 308, 3, 349, 341, 2913, 10, 143, 127, 5, 7690, 30, 4, 129, 5194, 1406, 2326, 5, 21025, 308, 10, 528, 12, 109, 1448, 4, 60, 543, 102, 12, 21025, 308, 6, 227, 4146, 48, 3, 2211, 12, 8, 215, 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y8mpqWHkKBg",
        "colab_type": "text"
      },
      "source": [
        "## Encoding Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fA-pWn4jvjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44d5da4a-f42f-4a0b-c69e-a6384b4200bb"
      },
      "source": [
        "# converting in 0 and 1\n",
        "labels_split = label.split('\\n')\n",
        "encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])\n",
        "print('total labels: ',len(encoded_labels))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total labels:  25001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoEx_An4kgHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "446ae34d-5d5e-4894-c5e0-919f915d63ea"
      },
      "source": [
        "review_length = Counter([len(x) for x in reviews_to_integer])\n",
        "print('Zero length review: {}'. format(review_length[0]))\n",
        "print('max length review: {}'.format(max(review_length)))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zero length review: 1\n",
            "max length review: 2514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAMwiAsbrXwZ",
        "colab_type": "text"
      },
      "source": [
        "Here, I need to remove such review which has empty revies. so first need to clear data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEyHY23JlBRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb67d054-50ee-43af-c4bb-6be4517c1558"
      },
      "source": [
        "print('Number of revies befoere removing outlier: ', len(reviews_to_integer))\n",
        "\n",
        "# get index of reviews with length 0\n",
        "non_zero_idx = [c for c, review in enumerate(reviews_to_integer) if len(review) != 0]\n",
        "\n",
        "# now remove it \n",
        "reviews_int = [reviews_to_integer[i] for i in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[i] for i in non_zero_idx])\n",
        "\n",
        "print('Number of review after the cleanup: ',len(reviews_int))\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of revies befoere removing outlier:  25001\n",
            "Number of review after the cleanup:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwMIS0bdxAN3",
        "colab_type": "text"
      },
      "source": [
        "## Padding Sequences \n",
        "\n",
        "The length of the sequences are uneven so first we need to make it to some constant value, here I will took 200 words/review. For short review, I will add 0 in null values. \n",
        "\n",
        "Here, I will add zero to left. And, its called left padding. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRPpPtl7zfUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_int,review_length):\n",
        "  features = np.zeros((len(reviews_int),review_length),dtype=int)\n",
        "\n",
        "  for i,row in enumerate(reviews_int):\n",
        "    features[i,-len(row):] = np.array(row)[:review_length]\n",
        "  return features"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxhNoNi44oMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "826c13ac-93d0-447d-8cc3-0d181b2eb4f1"
      },
      "source": [
        "review_length = 200\n",
        "features = pad_features((reviews_int), review_length=review_length)\n",
        "\n",
        "assert len(features) == len(reviews_int) \n",
        "assert len(features[0]) == review_length \n",
        "\n",
        "print(features[:30,:10])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [22382    42 46418    15   706 17139  3389    47    77    35]\n",
            " [ 4505   505    15     3  3342   162  8312  1652     6  4819]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   54    10    14   116    60   798   552    71   364     5]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    1   330   578    34     3   162   748  2731     9   325]\n",
            " [    9    11 10171  5305  1946   689   444    22   280   673]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    1   307 10399  2069  1565  6202  6528  3288 17946 10628]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   21   122  2069  1565   515  8181    88     6  1325  1182]\n",
            " [    1    20     6    76    40     6    58    81    95     5]\n",
            " [   54    10    84   329 26230 46427    63    10    14   614]\n",
            " [   11    20     6    30  1436 32317  3769   690 15100     6]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   40    26   109 17952  1422     9     1   327     4   125]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   10   499     1   307 10399    55    74     8    13    30]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZOJIwpL06zs",
        "colab_type": "text"
      },
      "source": [
        "## Data Set Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-39bbN-rw6Zp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "914240ce-aef2-4e60-b72c-819ffcb509d5"
      },
      "source": [
        "split_fraction = 0.8\n",
        "\n",
        "# split data into training, validation and test data\n",
        "\n",
        "split_idx = int(len(features)*split_fraction)\n",
        "train_x,remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y,remaining_y = features[:split_idx], features[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "# vizulize data\n",
        "print('\\t\\t\\tFeatures Shapes ')\n",
        "print('Training set: \\t{}'.format(train_x.shape),\n",
        "      '\\nValidation set: {}'.format(val_x.shape),\n",
        "      '\\nTest Set:\\t{}'.format(test_x.shape))\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeatures Shapes \n",
            "Training set: \t(20000, 200) \n",
            "Validation set: (2500, 200) \n",
            "Test Set:\t(2500, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z5qLq1e6rQy",
        "colab_type": "text"
      },
      "source": [
        "## DataLoader and Batching "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liBz-KyT06L4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "0d17bbe5-0840-4afd-e468-fe044704d12b"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# SHUFFLE training data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[    1, 13792,     6,  ...,   939,    99,   257],\n",
            "        [    0,     0,     0,  ...,    32,    31,  2175],\n",
            "        [    0,     0,     0,  ...,   202,  1115,    18],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,  5721,     9,   592],\n",
            "        [   22,     1,   386,  ...,    37,   113,    15],\n",
            "        [    0,     0,     0,  ...,     6,     3,  1400]])\n",
            "\n",
            "Sample label size:  torch.Size([50, 200])\n",
            "Sample label: \n",
            " tensor([[    1, 13792,     6,  ...,   939,    99,   257],\n",
            "        [    0,     0,     0,  ...,    32,    31,  2175],\n",
            "        [    0,     0,     0,  ...,   202,  1115,    18],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,  5721,     9,   592],\n",
            "        [   22,     1,   386,  ...,    37,   113,    15],\n",
            "        [    0,     0,     0,  ...,     6,     3,  1400]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRIrzpRm8fHe",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Network with PyTorch\n",
        "\n",
        "The layers are as follows:\n",
        "\n",
        "- An **embedding layer** that converts our word tokens (integers) into embeddings of a specific size.\n",
        "- An **LSTM layer** defined by a hidden_state size and number of layers\n",
        "- A **fully-connected output layer** that maps the LSTM layer outputs to a desired output_size\n",
        "- A **sigmoid activation layer** which turns all outputs into a value 0-1; return only the last sigmoid output as the output of this network.\n",
        "\n",
        "**The Embedding Layer** \n",
        "\n",
        "We need to add an embedding layer because there are 74000+ words in our vocabulary. It is massively inefficient to one-hot encode that many classes. So, instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. You could train an embedding layer using Word2Vec, then load it here. But, it's fine to just make a new layer, using it for only dimensionality reduction, and let the network learn the weights.\n",
        "\n",
        "**The LSTM Layer(s)**\n",
        "\n",
        "We'll create an LSTM to use in our recurrent network, which takes in an input_size, a hidden_dim, a number of layers, a dropout probability (for dropout between multiple layers), and a batch_first parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhsnGEAT6_SP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "182f8003-8f9a-4796-82a9-95415057926a"
      },
      "source": [
        "# first check gpu avaibility \n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available, training on CPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdsqXmje9rf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn \n",
        "\n",
        "class RNN_LSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob= 0.5):\n",
        "    super(RNN_LSTM,self).__init__()\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    # embedding and LSTM layers\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = drop_prob, batch_first = True)\n",
        "\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim,output_size)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x,hidden):\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    # embedding and lstm output\n",
        "    x = x.long()\n",
        "    embeds = self.embedding(x)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "    lstm_out = lstm_out.contiguous().view(-1,self.hidden_dim)\n",
        "\n",
        "    out = self.dropout(lstm_out)\n",
        "    out = self.fc(out)\n",
        "    sig_out = self.sig(out)\n",
        "\n",
        "    # reshape to be batch_size \n",
        "    sig_out = sig_out.view(batch_size, -1)\n",
        "    sig_out = sig_out[:,-1]\n",
        "\n",
        "    return sig_out, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    if (train_on_gpu):\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "           weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    else:\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                    weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "      \n",
        "      return hidden "
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4xV3CpHQlT5",
        "colab_type": "text"
      },
      "source": [
        "# run\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqfV37HeQlqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN_LSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.4):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(RNN_LSTM, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb_G68LA9rl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "37904e3d-0415-4a35-b259-339e7a1efc0a"
      },
      "source": [
        "# set paramers and initialize network \n",
        "\n",
        "vocab_size = len(vocab_to_integer)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = RNN_LSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN_LSTM(\n",
            "  (embedding): Embedding(74073, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.4)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgpjjkvUEVRG",
        "colab_type": "text"
      },
      "source": [
        "## Training \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-_blP3UEIIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwE9PhbaG6Ev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "a53abdb3-cf98-41dd-8db6-fd7e31904707"
      },
      "source": [
        "# training parameters\n",
        "epochs = 4\n",
        "counter = 0\n",
        "print_every = 100 \n",
        "clip = 5  # gradient clipping for gradient explodation\n",
        "\n",
        "if(train_on_gpu):\n",
        "  net.cuda()\n",
        "\n",
        "net.train()\n",
        "\n",
        "for e in range(epochs):\n",
        "  h = net.init_hidden(batch_size)\n",
        "\n",
        "  # batch loop\n",
        "  for inputs, labels in train_loader:\n",
        "    counter +=1\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    # reset gradient \n",
        "    net.zero_grad()\n",
        "\n",
        "    # get the output from the model \n",
        "    output,h = net(inputs, h)\n",
        "\n",
        "    # calculate loss \n",
        "    loss = criterion(output.squeeze(), labels.float())\n",
        "    loss.backward()\n",
        "\n",
        "    nn.utils.clip_grad_norm_(net.parameters(),ckop)\n",
        "    optimizer.step()\n",
        "\n",
        "    # loss state\n",
        "    if coutner % print_every == 0:\n",
        "      val_h = net.init_hidden(batch_size)\n",
        "      val_losses = []\n",
        "      net.eval()\n",
        "      for inputs, labels in valid_loader:\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "        if(train_on_gpu):\n",
        "          inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        output, val_h = net(inputs, val_h)\n",
        "        val_loss = criterion(output.squeeze(), labels.float())\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "      net.train()\n",
        "      print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([50, 200])) that is different to the input size (torch.Size([50])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-160-0774041c134d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2475\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[0;32m-> 2477\u001b[0;31m                          \"!= input nelement ({})\".format(target.numel(), input.numel()))\n\u001b[0m\u001b[1;32m   2478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (10000) != input nelement (50)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZNEoA7rPs22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}